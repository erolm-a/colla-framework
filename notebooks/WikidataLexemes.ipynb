{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikidata lexicon (~ Wiktionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset L536.json not available, downloading from https://wikidata.org/wiki/Special:EntityData/L536.json\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from tools.datasets import *\n",
    "\n",
    "book = \"L536\"\n",
    "\n",
    "book_df = fetch_dataset(book, provider=\"wikidata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikidata lexemes breakdown structure\n",
    "\n",
    "(cfr. Wikidata.ipynb). The online documentation on lexemes is pretty limited.\n",
    "\n",
    "A lexeme is a unit of lexical meaning. Morphologically speaking it can only belong to one grammatical category. Homographical lexemes (P5402) are stored as different lexemes. In this case, L536 refers to book as a noun\n",
    "\n",
    "- `lemmas`: array of lemmas of a lexeme.\n",
    "    - `#lang` (e.g. `en`): contains the basic lemma in one or more language (lang->value). In general, the word could be valid in more languages.\n",
    "    - `lexicalCategory`: an entity describing the grammatical category (verb, noun...)\n",
    "    - `language`: a lexema only corresponds to a single language. Even here, just an entity\n",
    "- `claims`: Structured like normal wikidata claims, contains grammatical features of the main lexeme and other relationships not related to senses, glosses or morphological forms. For example, `P5185` is the grammatical gender, `P5402` is a homograph lexeme.\n",
    "- `forms`: an array of morphological forms. Each form is called L{ENTITY_NAME}-F{NO} with NO starting from 1.\n",
    "    - `Ã¬d`\n",
    "    - `representations`: like for `#lang` above, but this time it represents a morphological variation.\n",
    "    - `grammaticalFeatures`: an array of grammatical features\n",
    "- `senses`: array of senses (either a translation or a definition, depending on the start and end language)\n",
    "    - `claims`: the structure is similar to a normal claim in wikidata, but the number of predicates is circumscribed to:\n",
    "        - `P5972: translation`: bring to senses (of the form `wd:LX-SN` where `LX` is a lexeme and `SN` is the sense number starting from S1. Human-readable annotations can be found by querying their label (`rdfs:label` or `skos:definition` on the dataset).\n",
    "        - `P5137: item for this sense`: the corresponding Wikidata Entity\n",
    "        - a few others (`P18: image`, ...)\n",
    "    - `glosses`: categorises the noun. Mainly used to disambiguate word senses. Like for `#lang` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "book_pd = pd.json_normalize(book_df[\"entities\"][\"L536\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pageid', 'ns', 'title', 'lastrevid', 'modified', 'type', 'id',\n",
       "       'lexicalCategory', 'language', 'forms', 'senses', 'lemmas.en.language',\n",
       "       'lemmas.en.value', 'claims.P5402'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_pd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data\n",
    "\n",
    "We are collecting the top 1000 most used worst according to Wikidictionary. The counts are based on the absolute word frequency extracted from TV series and movie scripts in public domain till 2006. More details [here](https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/TV/2006/1-1000). From here on, we'll refer to them as WDTV.\n",
    "\n",
    "Similarly, we compare with an extraction from Project Gutemberg (synced 2006 - is there anything more modern?) (WDPG) and hunspell-en-gb -ise (HUN-GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape wdtv\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "def scrape_wiktionary(url):\n",
    "    r = get(url)\n",
    "    parsed = BeautifulSoup(r.content, \"html.parser\")\n",
    "    tables = parsed.find_all(\"table\")\n",
    "    table = tables[0]\n",
    "    rows = table.find_all(\"tr\")[1:]\n",
    "    cols = [row.find_all(\"td\")[1].find(\"a\").text for row in rows]\n",
    "    \n",
    "    return cols\n",
    "\n",
    "\n",
    "    \n",
    "wdtv_list = scrape_wiktionary(\"https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/TV/2006/1-1000\")\n",
    "wdpg_list = scrape_wiktionary(\"https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/PG/2006/04/1-10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hunspell(dataset):\n",
    "    # Remove the gender/plurality annotation\n",
    "    with wrap_open(join(\"wordlists\", dataset)) as f:\n",
    "        num_of_words = int(f.readline())\n",
    "        return [row.split(\"/\")[0] for idx, row in enumerate(f.readlines()) if idx < num_of_words]\n",
    "\n",
    "\n",
    "hun_en_gb = hunspell(\"en_GB-ise.dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
