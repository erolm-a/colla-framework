{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sippycup semantic parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('3rdparty/sippycup')\n",
    "from annotator import *\n",
    "from parsing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rule(grammar, rule):\n",
    "    if contains_optionals(rule):\n",
    "        add_rule_containing_optional(grammar, rule)\n",
    "    elif is_lexical(rule):\n",
    "        grammar.lexical_rules[rule.rhs].append(rule)\n",
    "    elif is_unary(rule):\n",
    "        grammar.unary_rules[rule.rhs].append(rule)\n",
    "    elif is_binary(rule):\n",
    "        grammar.binary_rules[rule.rhs].append(rule)\n",
    "    elif all([is_cat(rhsi) for rhsi in rule.rhs]):\n",
    "        add_n_ary_rule(grammar, rule)\n",
    "    else:\n",
    "        make_cat(grammar, rule)\n",
    "        # raise Exception('RHS mixes terminals and non-terminals: %s' % rule\n",
    "\n",
    "def add_rule_containing_optional(grammar, rule):\n",
    "    # Find index of the first optional element on the RHS.\n",
    "    first = next((idx for idx, elt in enumerate(rule.rhs) if is_optional(elt)), -1)\n",
    "    assert first >= 0\n",
    "    assert len(rule.rhs) > 1, 'Entire RHS is optional: %s' % rule\n",
    "    prefix = rule.rhs[:first]\n",
    "    suffix = rule.rhs[(first + 1):]\n",
    "    # First variant: the first optional element gets deoptionalized.\n",
    "    deoptionalized = (rule.rhs[first][1:],)\n",
    "    add_rule(grammar, Rule(rule.lhs, prefix + deoptionalized + suffix, rule.sem))\n",
    "    # Second variant: the first optional element gets removed.\n",
    "    # If the semantics is a value, just keep it as is.\n",
    "    sem = rule.sem\n",
    "    # But if it's a function, we need to supply a dummy argument for the removed element.\n",
    "    if isinstance(rule.sem, FunctionType):\n",
    "        sem = lambda sems: rule.sem(sems[:first] + [None] + sems[first:])\n",
    "    add_rule(grammar, Rule(rule.lhs, prefix + suffix, sem))\n",
    "\n",
    "def make_cat(grammar, rule):\n",
    "    \"\"\"\n",
    "    Convert a terminal in the RHS into a non-terminal.\n",
    "    \n",
    "    Conversion works by creating a nonterminal from each terminal if\n",
    "    it does not exist already in the grammar, otherwise it just replaces it.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_rhs = []\n",
    "    for rhsi in rule.rhs:\n",
    "        if is_cat(rhsi):\n",
    "            cat_name = rhsi\n",
    "        else:\n",
    "            cat_name = \"$\" + rhsi + \"__nonterminal\"\n",
    "            if cat_name not in grammar.categories:\n",
    "                grammar.categories.add(cat_name)\n",
    "                # print(f\"Adding rule: {cat_name} := {str(rhsi)}\")\n",
    "                add_rule(grammar, Rule(cat_name, rhsi))\n",
    "        new_rhs.append(cat_name)\n",
    "        # print(f\"Adding rule: {rule.lhs} := {str(new_rhs)}\")\n",
    "    add_rule(grammar, Rule(rule.lhs, tuple(new_rhs), rule.sem))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(grammar, input):\n",
    "    \"\"\"Returns a list of all parses for input using grammar.\"\"\"\n",
    "    tokens_spacy = nlp(input) # New\n",
    "    tokens = [token.text for token in tokens_spacy]\n",
    "    chart = defaultdict(list)\n",
    "    for j in range(1, len(tokens) + 1):\n",
    "        for i in range(j - 1, -1, -1):\n",
    "            apply_annotators(grammar, chart, tokens, i, j)\n",
    "            apply_lexical_rules(grammar, chart, tokens, i, j)\n",
    "            apply_binary_rules(grammar, chart, i, j)\n",
    "            apply_unary_rules(grammar, chart, i, j)\n",
    "    parses = chart[(0, len(tokens))]\n",
    "    if hasattr(grammar, 'start_symbol') and grammar.start_symbol:\n",
    "        parses = [parse for parse in parses if parse.rule.lhs == grammar.start_symbol]\n",
    "    return parses\n",
    "\n",
    "class Grammar:\n",
    "    def __init__(self, rules=[], annotators=[], start_symbol='$ROOT'):\n",
    "        self.categories = set()\n",
    "        self.lexical_rules = defaultdict(list)\n",
    "        self.unary_rules = defaultdict(list)\n",
    "        self.binary_rules = defaultdict(list)\n",
    "        self.annotators = annotators\n",
    "        self.start_symbol = start_symbol\n",
    "        for rule in rules:\n",
    "            add_rule(self, rule)\n",
    "        print('Created grammar with %d rules.' % len(rules))\n",
    "\n",
    "    def parse_input(self, input):\n",
    "        \"\"\"Returns a list of parses for the given input.\"\"\"\n",
    "        return parse_input(self, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$Number', 16)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumberAnnotator().annotate(['16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$Token', 'foo')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenAnnotator().annotate(['foo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWordAnnotator(Annotator):\n",
    "    \"\"\"Let spacy detect stop words for us\"\"\"\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) == 1:\n",
    "            if nlp(tokens[0])[0].is_stop:\n",
    "                return [('$StopWord', tokens[0])]\n",
    "        return []\n",
    "\n",
    "class ShowVerbAnnotator(Annotator):\n",
    "    def __init__(self, threshold = 0.7):\n",
    "        self.show_verbs = [(\"define\", \"\"), (\"tell\", \"me\"), (\"show\", \"me\")]\n",
    "        self.spacy_show_toks = nlp(\" \".join([verb for verb, _ in self.show_verbs]))\n",
    "        self.threshold = 0.7\n",
    "\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) <= 2:\n",
    "            spacy_tokens = nlp(\" \".join(tokens))\n",
    "            spacy_token = spacy_tokens[0]\n",
    "            if spacy_token.pos_ != 'VERB':\n",
    "                return []\n",
    "            \n",
    "            # If the verb matches in meaning and, in case it requires a\n",
    "            # follow-up word, that this matches as well, then it's a match.\n",
    "            for idx, (verb, acc) in enumerate(self.show_verbs):\n",
    "                spacy_verb = self.spacy_show_toks[idx]\n",
    "                if spacy_token.similarity(spacy_verb) >= self.threshold:\n",
    "                    if verb == tokens[0] and acc != \"\" and (len(tokens) == 1 or tokens[1] != acc):\n",
    "                        return []\n",
    "                    return [('$ShowVerb', tokens)]\n",
    "        return []\n",
    "\n",
    "    \n",
    "class TokenAnnotatorBuilder(Annotator):\n",
    "    def __init__(self, category_name, excluded):\n",
    "        Annotator.__init__(self)\n",
    "        self.category_name = category_name\n",
    "        self.excluded = excluded\n",
    "    \n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) == 1:\n",
    "            token = tokens[0]\n",
    "            if token not in self.excluded:\n",
    "                return [(self.category_name, token)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['say'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['say'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['define'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['define'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['tell', 'me'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['tell', 'me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TokenWithoutQuotes', 'Jeff')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenAnnotatorBuilder('TokenWithoutQuotes', ['\"', '\"']).annotate(['Jeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CELL_CAPACITY = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar definition\n",
    "\n",
    "We will model the queries after a few intents:\n",
    "\n",
    "- Definition: asking for a definition of a noun phrase\n",
    "- Comparison: compare two noun phrases\n",
    "- Filtering/Details on a given sense: ask for further details on a previously mentioned sense\n",
    "- Usage of form\n",
    "- General grammar knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def sems_0(sems):\n",
    "    return sems[0]\n",
    "\n",
    "def sems_1(sems):\n",
    "    return sems[1]\n",
    "\n",
    "def sems_2(sems):\n",
    "    return sems[2]\n",
    "\n",
    "def merge_dicts(d1, d2):\n",
    "    if not d2:\n",
    "        return d1\n",
    "    if not d1:\n",
    "        return {}\n",
    "    return {**d1, **d2}\n",
    "\n",
    "def strip_none(sems):\n",
    "    return [sem for sem in sems if sem]\n",
    "\n",
    "def merge_dicts_singleparam(sems):\n",
    "    if all([sem is None for sem in sems]):\n",
    "        return {}\n",
    "    return reduce(merge_dicts, strip_none(sems))\n",
    "\n",
    "def to_np(sems):\n",
    "    return {'np': strip_none(sems)[0]}\n",
    "\n",
    "def concatenate(sems):\n",
    "    return \" \".join(strip_none(sems))\n",
    "\n",
    "\n",
    "rules_definition = [\n",
    "    Rule('$ROOT', '$DefinitionQuery', sems_0),\n",
    "    Rule('$DefinitionQuery', '$DefinitionQueryElements',\n",
    "         lambda sems: merge_dicts({'intent': 'define'}, sems[0])),\n",
    "    Rule('$DefinitionQueryElements', '$DefinitionQuestion $NounPhrase',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    # Special case: \"what does X mean?\"\n",
    "    Rule('$DefinitionQueryElements', 'what does $NounPhrase mean', sems_2),\n",
    "    \n",
    "    Rule('$DefinitionQuestion', '$ShowVerb ?me ?$Determiner'),\n",
    "    Rule('$DefinitionQuestion', '$ShowVerb ?me $WhoDefinition'),\n",
    "    Rule('$DefinitionQuestion', '$ShowVerb ?me $WhatDefinition'),\n",
    "    Rule('$DefinitionQuestion', '$WhatDefinition'),\n",
    "    Rule('$DefinitionQuestion', '$WhoDefinition', {'isPerson': True}),\n",
    "    Rule('$WhoDefinition', 'who $Be'),\n",
    "    Rule('$WhatDefinition', 'what $Be ?$Determiner ?$DefinitionFor'),\n",
    "    Rule('$WhatDefinition', 'how do you $ShowVerb'),\n",
    "    Rule('$DefinitionFor', '$WordSense $StopWord'),\n",
    "    Rule('$NounPhrase', \"$Tokens\", to_np),\n",
    "    Rule('$NounPhrase', \"' $Tokens '\", to_np),\n",
    "    Rule('$NounPhrase', '\" $Tokens \"', to_np),\n",
    "    Rule('$Tokens', '$UnquotedToken ?$Tokens', concatenate)\n",
    "]\n",
    "\n",
    "rules_determiner = [\n",
    "    Rule('$Determiner', 'a'),\n",
    "    Rule('$Determiner', 'an'),\n",
    "    Rule('$Determiner', 'the'),\n",
    "    Rule('$Determiner', 'about the'),\n",
    "    Rule('$Determiner', 'its'),\n",
    "    Rule('$Determiner', \"any\"),\n",
    "    Rule('$Determiner', \"some\"),\n",
    "]\n",
    "\n",
    "rules_be = [\n",
    "    Rule(\"$Be\", \"is\"),\n",
    "    Rule(\"$Be\", \"are\"),\n",
    "    Rule(\"$Be\", \"'s\"),\n",
    "    Rule(\"$Be\", \"were\"),\n",
    "    Rule(\"$Be\", \"was\"),\n",
    "    Rule(\"$Be\", \"be\"),\n",
    "    Rule(\"$Be\", \"being\"),\n",
    "]\n",
    "\n",
    "rules_wordsenses = [\n",
    "    Rule(\"$WordSense\", \"one\"),\n",
    "    Rule(\"$WordSense\", \"sense\"),\n",
    "    Rule(\"$WordSense\", \"meaning\"),\n",
    "    Rule(\"$WordSense\", \"definition\"),\n",
    "    Rule(\"$WordSense\", \"definitions\"),\n",
    "    Rule(\"$WordSense\", \"possibility\"),\n",
    "    Rule(\"$WordSense\", \"possibilities\"),\n",
    "    Rule(\"$WordSense\", \"case\"),\n",
    "    Rule(\"$WordSense\", \"field\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 40 rules.\n"
     ]
    }
   ],
   "source": [
    "annotators = [StopWordAnnotator(), ShowVerbAnnotator(), TokenAnnotatorBuilder(\"$UnquotedToken\", [\"'\", '\"', \"?\"])]\n",
    "rules = rules_definition + rules_determiner + rules_be + rules_wordsenses\n",
    "grammar = Grammar(rules=rules, annotators=annotators)\n",
    "parses = grammar.parse_input('define pi')\n",
    "parse = parses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'define', 'np': 'pi'}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse.semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input('define \"pi\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'define', 'isPerson': True, 'np': 'apollo'}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.parse_input('who is apollo')[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'define', 'np': 'pi'}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $ROOT ('$DefinitionQuery',)\n",
      "|\n",
      "-- $DefinitionQuery ('$DefinitionQueryElements',)\n",
      "|\n",
      "---- $DefinitionQueryElements ('$DefinitionQuestion', '$NounPhrase')\n",
      "|\n",
      "------ $DefinitionQuestion ('$ShowVerb',)\n",
      "|\n",
      "-------- $ShowVerb ('define',)\n",
      "|\n",
      "------ $NounPhrase ('$\"__nonterminal', '$NounPhrase_$\"__nonterminal')\n",
      "|\n",
      "-------- $\"__nonterminal ('\"',)\n",
      "|\n",
      "-------- $NounPhrase_$\"__nonterminal ('$Tokens', '$\"__nonterminal')\n",
      "|\n",
      "---------- $Tokens ('$UnquotedToken',)\n",
      "|\n",
      "------------ $UnquotedToken ('pi',)\n",
      "|\n",
      "---------- $\"__nonterminal ('\"',)\n"
     ]
    }
   ],
   "source": [
    "def pretty_print(parse, depth=0):\n",
    "    if not isinstance(parse, str):\n",
    "        if depth > 0:\n",
    "            for _ in range(1):\n",
    "                print(\"|\")\n",
    "        print(\"-\" * depth * 2, parse.rule.lhs, parse.rule.rhs)\n",
    "        for child in parse.children:\n",
    "            pretty_print(child, depth+1)\n",
    "\n",
    "pretty_print(parses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parse(grammar, utterances):\n",
    "    for utterance in utterances:\n",
    "        print(\"=\" * 20)\n",
    "        print(\"For the utterance \" + utterance + \":\")\n",
    "        for parse in grammar.parse_input(utterance):\n",
    "            print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "For the utterance define pie:\n",
      "{'intent': 'define', 'np': 'pie'}\n",
      "====================\n",
      "For the utterance tell me about the life:\n",
      "{'intent': 'define', 'np': 'about the life'}\n",
      "{'intent': 'define', 'np': 'life'}\n",
      "====================\n",
      "For the utterance what is an 'apple':\n",
      "{'intent': 'define', 'np': 'apple'}\n",
      "====================\n",
      "For the utterance what is the definition of botanics:\n",
      "{'intent': 'define', 'np': 'the definition of botanics'}\n",
      "{'intent': 'define', 'np': 'definition of botanics'}\n",
      "{'intent': 'define', 'np': 'botanics'}\n",
      "====================\n",
      "For the utterance what does mechanophilia mean:\n",
      "{'intent': 'define', 'np': 'mechanophilia'}\n",
      "====================\n",
      "For the utterance what is apollo:\n",
      "{'intent': 'define', 'np': 'apollo'}\n",
      "====================\n",
      "For the utterance who is apollo:\n",
      "{'intent': 'define', 'isPerson': True, 'np': 'apollo'}\n",
      "====================\n",
      "For the utterance what are ants:\n",
      "{'intent': 'define', 'np': 'ants'}\n",
      "====================\n",
      "For the utterance what are definitions for love:\n",
      "{'intent': 'define', 'np': 'definitions for love'}\n",
      "{'intent': 'define', 'np': 'love'}\n"
     ]
    }
   ],
   "source": [
    "# parses = grammar.parse_input(\"define 'pi'\")\n",
    "define_utterances = [\"define pie\", \"tell me about the life\", \"what is an 'apple'\",\n",
    "                         \"what is the definition of botanics\", \"what does mechanophilia mean\",\n",
    "                         \"what is apollo\", \"who is apollo\", \"what are ants\",\n",
    "                         \"what are definitions for love\"]\n",
    "print_parse(grammar, define_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter intents\n",
    "\n",
    "- \"show me the third sense\"\n",
    "- \"tell me more about the mathematical meaning\"\n",
    "- \"show me some examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_to_num import alpha2digit\n",
    "\n",
    "def remove_suffix(word: str, suffix: str):\n",
    "    \"\"\"Remove a suffix from a string. \"\"\"\n",
    "    if word.endswith(suffix):\n",
    "        return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "def convert_ordinal(word: str):\n",
    "    \"\"\"Convert a number to ordinal\"\"\"\n",
    "    basic_forms = {\"first\": \"one\",\n",
    "                   \"second\": \"two\",\n",
    "                   \"third\": \"three\",\n",
    "                   \"fifth\": \"five\",\n",
    "                   \"twelfth\": \"twelve\"}\n",
    "    \n",
    "    for k, v in basic_forms.items():\n",
    "        word = word.replace(k, v)\n",
    "    \n",
    "    word = word.replace(\"ieth\", \"y\")\n",
    "    \n",
    "    for pattern in [\"st\", \"nd\", \"rd\", \"th\", \"°\"]:\n",
    "        word = remove_suffix(word, pattern)\n",
    "    \n",
    "    converted = alpha2digit(word, \"en\")\n",
    "    try:\n",
    "        return int(converted)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "class OrdinalNumberAnnotator(Annotator):\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) > 1:\n",
    "            return []\n",
    "        value = convert_ordinal(tokens[0])\n",
    "        if value:\n",
    "            return [('$OrdinalNumber', value)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$OrdinalNumber', 40)]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrdinalNumberAnnotator().annotate(['fortieth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tools.dumps import wrap_open\n",
    "\n",
    "with wrap_open(\"wikidata/grammatical_categories.json\") as fp:\n",
    "    categories = pd.read_json(fp)\n",
    "    \n",
    "categories_set = set(categories[\"entityLabel.value\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"plural\" in categories_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity.value</th>\n",
       "      <th>entityLabel.value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>http://www.wikidata.org/entity/Q192613</td>\n",
       "      <td>present tense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1240211</td>\n",
       "      <td>present perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>http://www.wikidata.org/entity/Q3502553</td>\n",
       "      <td>present subjunctive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>http://www.wikidata.org/entity/Q7240943</td>\n",
       "      <td>present continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>http://www.wikidata.org/entity/Q9062494</td>\n",
       "      <td>present perfect in English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>http://www.wikidata.org/entity/Q10345583</td>\n",
       "      <td>present participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434162</td>\n",
       "      <td>present imperative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434245</td>\n",
       "      <td>present infinitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434511</td>\n",
       "      <td>present gerund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>http://www.wikidata.org/entity/Q56682909</td>\n",
       "      <td>present indicative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1763348</td>\n",
       "      <td>present participe in French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>http://www.wikidata.org/entity/Q10345583</td>\n",
       "      <td>present participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434245</td>\n",
       "      <td>present infinitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>http://www.wikidata.org/entity/Q12738495</td>\n",
       "      <td>present perfect continuous in English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>http://www.wikidata.org/entity/Q56649265</td>\n",
       "      <td>present imperfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>http://www.wikidata.org/entity/Q12738495</td>\n",
       "      <td>present perfect continuous in English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>http://www.wikidata.org/entity/Q12738495</td>\n",
       "      <td>present perfect continuous in English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 entity.value  \\\n",
       "136    http://www.wikidata.org/entity/Q192613   \n",
       "144   http://www.wikidata.org/entity/Q1240211   \n",
       "152   http://www.wikidata.org/entity/Q3502553   \n",
       "156   http://www.wikidata.org/entity/Q7240943   \n",
       "157   http://www.wikidata.org/entity/Q9062494   \n",
       "158  http://www.wikidata.org/entity/Q10345583   \n",
       "174  http://www.wikidata.org/entity/Q52434162   \n",
       "175  http://www.wikidata.org/entity/Q52434245   \n",
       "177  http://www.wikidata.org/entity/Q52434511   \n",
       "180  http://www.wikidata.org/entity/Q56682909   \n",
       "203   http://www.wikidata.org/entity/Q1763348   \n",
       "218  http://www.wikidata.org/entity/Q10345583   \n",
       "224  http://www.wikidata.org/entity/Q52434245   \n",
       "232  http://www.wikidata.org/entity/Q12738495   \n",
       "233  http://www.wikidata.org/entity/Q56649265   \n",
       "340  http://www.wikidata.org/entity/Q12738495   \n",
       "400  http://www.wikidata.org/entity/Q12738495   \n",
       "\n",
       "                         entityLabel.value  \n",
       "136                          present tense  \n",
       "144                        present perfect  \n",
       "152                    present subjunctive  \n",
       "156                     present continuous  \n",
       "157             present perfect in English  \n",
       "158                     present participle  \n",
       "174                     present imperative  \n",
       "175                     present infinitive  \n",
       "177                         present gerund  \n",
       "180                     present indicative  \n",
       "203            present participe in French  \n",
       "218                     present participle  \n",
       "224                     present infinitive  \n",
       "232  present perfect continuous in English  \n",
       "233                      present imperfect  \n",
       "340  present perfect continuous in English  \n",
       "400  present perfect continuous in English  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[categories['entityLabel.value'].str.startswith(\"present\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adverb',\n",
       " 'verb',\n",
       " 'noun',\n",
       " 'propername',\n",
       " 'determiner',\n",
       " 'preposition',\n",
       " 'adjective',\n",
       " 'interjection',\n",
       " 'conjunction',\n",
       " 'particle',\n",
       " 'pronoun',\n",
       " 'adposition',\n",
       " 'affix',\n",
       " 'article',\n",
       " 'postposition',\n",
       " 'letter',\n",
       " 'prefix',\n",
       " 'proverb',\n",
       " 'punctuation',\n",
       " 'symbol',\n",
       " 'suffix']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tools.providers import FusekiProvider\n",
    "\n",
    "fuseki_provider = FusekiProvider()\n",
    "poses = fuseki_provider.dump_pos_categories()['posEntity'].str[4:]\n",
    "poses.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSAnnotator(Annotator):\n",
    "    pos_categories = fuseki_provider.dump_pos_categories()['posEntity'].str[4:].to_list()\n",
    "    \n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) != 1:\n",
    "            return []\n",
    "        # get the singular for the POS\n",
    "        candidate = nlp(tokens[0])[0].lemma_\n",
    "        if candidate in POSAnnotator.pos_categories:\n",
    "            return [('$POS', candidate)]\n",
    "        return []\n",
    "\n",
    "\n",
    "class GrammaticalFeatureAnnotator:\n",
    "    def annotate(self, tokens):\n",
    "        candidate = \" \".join(tokens)\n",
    "        if candidate in categories_set:\n",
    "            return [(\"$GrammaticalFeature\", candidate)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    countable\n",
       "1          usually uncountable\n",
       "2               not comparable\n",
       "3              comparable-only\n",
       "4     generally not comparable\n",
       "5                    defective\n",
       "6                  uncountable\n",
       "7                    irregular\n",
       "8             uncertain plural\n",
       "9            unattested plural\n",
       "10                    positive\n",
       "11                 comparative\n",
       "12                 superlative\n",
       "Name: grammaticalCategoryLabel.value, dtype: object"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuseki_provider.fetch_all_grammatical_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(type_):\n",
    "    def f(sems):\n",
    "        return merge_dicts({'filtertype': type_, 'value': sems[4]}, sems[1])\n",
    "    return f\n",
    "\n",
    "def as_constraint(sem):\n",
    "    return {'constraints': sem}\n",
    "    \n",
    "\n",
    "rules_filter = [\n",
    "    Rule('$ROOT', '$FilterQuery', lambda sems: merge_dicts({'intent': 'filter'}, sems[0])),\n",
    "    # Tell me about...\n",
    "    Rule('$FilterQuery', '?$ShowVerb $FilterQueryElements', sems_1),\n",
    "    Rule('$FilterQuery', '?$ShowVerb ?$StopWord $FilterQueryElements', sems_2),\n",
    "    # What about...\n",
    "    Rule('$FilterQuery', 'what about $FilterQueryElements', sems_2),\n",
    "    # What are the...\n",
    "    Rule('$FilterQuery', 'what $Be ?$Determiner $FilterQueryElements', lambda sems: sems[3]),\n",
    "    # \"which examples are available?\"\n",
    "    Rule('$FilterQuery', 'what $FilterQueryElements $be $More', sems_1),\n",
    "    Rule('$FilterQuery', 'which $FilterQueryElements $be $More', sems_1),\n",
    "    Rule('$FilterQuery', '$FilterQueryElements', sems_0),\n",
    "    \n",
    "    \n",
    "    # ordinal case\n",
    "    Rule('$FilterQueryElements', \"?$More the $OrdinalNumber ?$WordSense ?$Only\",\n",
    "         lambda sems: {'filtertype': 'number', 'value': strip_none(sems)[0]}),\n",
    "         \n",
    "    # \"more about the mathematical case\"\n",
    "    Rule('$FilterQueryElements', \"?$More the $UnquotedToken $WordSense ?$Only\",\n",
    "         lambda sems: {'filtertype': 'semantic', \"value\": strip_none(sems)[0]}),\n",
    "    \n",
    "    # some examples\n",
    "    Rule('$FilterQueryElements', '?$More $Extra', sems_1),\n",
    "    # some examples for the second case\n",
    "    Rule('$FilterQueryElements', '?$More $Extra $StopWord ?$Determiner $OrdinalNumber $WordSense ?$Only',\n",
    "         #lambda sems: merge_dicts({'type': 'number', 'value': sems[4]}, sems[1])),\n",
    "         foo('number')),\n",
    "         \n",
    "    # some examples for the botanical case\n",
    "    Rule('$FilterQueryElements', '?$More $Extra $StopWord ?$Determiner $UnquotedToken $WordSense ?$Only',\n",
    "         # lambda sems: merge_dicts({'type': 'sense_meaning', 'value': sems[4]}, sems[1])),\n",
    "         foo('semantic')),\n",
    "\n",
    "    # some examples as a verb\n",
    "    Rule('$FilterQueryElements', '?$More $Extra ?$Filler $StopWord ?$Determiner $POS',\n",
    "         # lambda sems: merge_dicts({'type': 'sense_meaning', 'value': sems[4]}, sems[1])),\n",
    "         lambda sems: merge_dicts({'filtertype': 'grammatical', 'requiredPos': sems[5]}, sems[1])),\n",
    "    \n",
    "    # Show me the plural form\n",
    "    Rule(\"$FilterQueryElements\", \"$Determiner $GrammaticalFeature ?form\",\n",
    "         lambda sems: {'filtertype': 'grammatical', 'grammaticalFeature': sems[1]}),\n",
    "    \n",
    "    # Ask for examples, categories or usages\n",
    "    Rule('$Extra', 'examples', {'variant': \"example\"}),\n",
    "    Rule('$Extra', 'categories', {'variant': \"categories\"}),\n",
    "    Rule('$Extra', 'usages', {'variant': \"usages\"}),\n",
    "    Rule('$Extra', 'senses', {'variant': \"senses\"}),\n",
    "    Rule('$Extra', 'parts of speech', {'variant': \"pos\"}),\n",
    "    Rule('$Extra', 'conjugate', {'variant': \"forms\"}),\n",
    "    Rule('$Extra', 'conjugation', {'variant': \"forms\"}),\n",
    "    Rule('$Extra', 'forms', {'variant': \"forms\"}),\n",
    "    \n",
    "    # Category question where category precedes the rest\n",
    "    Rule('$FilterQuery', \"$FilterCategoryQuery\",\n",
    "         lambda sems: merge_dicts({'filtertype': 'semantic'}, sems[0])),\n",
    "    # in the field of computer science, what does x mean?\n",
    "    Rule('$FilterCategoryQuery', \"$Category $WhatFilter\", sems_0),\n",
    "    Rule('$FilterCategoryQuery', \"$WhatFilter $Category\", sems_1),\n",
    "    Rule('$FilterCategoryQuery', \"$Category $?More $Extra\", merge_dicts_singleparam),\n",
    "    \n",
    "    \n",
    "    Rule('$More', \"more\"),\n",
    "    Rule('$More', \"more about\"),\n",
    "    Rule('$More', \"some\"),\n",
    "    Rule('$More', \"some some\"),\n",
    "    Rule('$More', \"any\"),\n",
    "    Rule('$More', 'possible'),\n",
    "    Rule('$More', 'available'),\n",
    "\n",
    "    \n",
    "    Rule(\"$Only\", \"only\"),\n",
    "    Rule(\"$Only\", \"alone\"),\n",
    "    \n",
    "    # for \"X\", as in \"show me more examples for 'snow\"\n",
    "    Rule(\"$Filler\", \"$StopWord $NounPhrase\"),\n",
    "    \n",
    "    Rule(\"$Category\", \"in $Determiner $WordSense $StopWord $NounPhrase ?,\", lambda sems: {'category': sems[4]['np']}),\n",
    "    Rule(\"$WhatFilter\", \"what does $NounPhrase mean\"),\n",
    "    Rule(\"$WhatFilter\", \"what $Be $Determiner $WordSense\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 79 rules.\n"
     ]
    }
   ],
   "source": [
    "annotators = [StopWordAnnotator(), ShowVerbAnnotator(),\n",
    "                TokenAnnotatorBuilder(\"$UnquotedToken\", [\"'\", '\"', \"?\", \",\"]), # commas must split noun phrases\n",
    "                OrdinalNumberAnnotator(), POSAnnotator(),\n",
    "                GrammaticalFeatureAnnotator()]\n",
    "\n",
    "rules_2 = rules_definition + rules_determiner + rules_filter + rules_be + rules_wordsenses\n",
    "\n",
    "grammar_2 = Grammar(rules=rules_2, annotators=annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "For the utterance tell me the first one:\n",
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first'}\n",
      "{'intent': 'filter', 'filtertype': 'number', 'value': 1}\n",
      "{'intent': 'define', 'np': 'the first one'}\n",
      "{'intent': 'define', 'np': 'first one'}\n",
      "====================\n",
      "For the utterance tell me the mathematical one only:\n",
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'mathematical'}\n",
      "{'intent': 'define', 'np': 'the mathematical one only'}\n",
      "{'intent': 'define', 'np': 'mathematical one only'}\n",
      "====================\n",
      "For the utterance tell me more examples:\n",
      "{'intent': 'filter', 'variant': 'example'}\n",
      "{'intent': 'define', 'np': 'more examples'}\n",
      "====================\n",
      "For the utterance what about more examples for the first one:\n",
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}\n",
      "====================\n",
      "For the utterance show me more examples for the chemistry one:\n",
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'chemistry', 'variant': 'example'}\n",
      "{'intent': 'define', 'np': 'more examples for the chemistry one'}\n",
      "====================\n",
      "For the utterance show me more examples as a noun:\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'noun', 'variant': 'example'}\n",
      "{'intent': 'define', 'np': 'more examples as a noun'}\n",
      "====================\n",
      "For the utterance show me more examples of home as a verb:\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'define', 'np': 'more examples of home as a verb'}\n",
      "====================\n",
      "For the utterance more examples of home as a verb:\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "====================\n",
      "For the utterance in the field of biology, what is the definition:\n",
      "{'intent': 'filter', 'filtertype': 'semantic', 'category': 'biology'}\n",
      "====================\n",
      "For the utterance what does it mean in the field of computer science:\n",
      "{'intent': 'filter', 'filtertype': 'semantic', 'category': 'computer science'}\n",
      "====================\n",
      "For the utterance tell me the singular form:\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'grammaticalFeature': 'singular'}\n",
      "{'intent': 'define', 'np': 'the singular form'}\n",
      "{'intent': 'define', 'np': 'singular form'}\n",
      "====================\n",
      "For the utterance more examples:\n",
      "{'intent': 'filter', 'variant': 'example'}\n",
      "{'intent': 'filter', 'variant': 'example'}\n",
      "====================\n",
      "For the utterance what are the available parts of speech:\n",
      "{'intent': 'filter', 'variant': 'pos'}\n",
      "{'intent': 'define', 'np': 'the available parts of speech'}\n",
      "{'intent': 'define', 'np': 'available parts of speech'}\n"
     ]
    }
   ],
   "source": [
    "filter_utterances = [\"tell me the first one\", \"tell me the mathematical one only\",\n",
    "                         \"tell me more examples\", \"what about more examples for the first one\",\n",
    "                         \"show me more examples for the chemistry one\", \"show me more examples as a noun\",\n",
    "                         \"show me more examples of home as a verb\", \"more examples of home as a verb\",\n",
    "                         \"in the field of biology, what is the definition\",\n",
    "                         \"what does it mean in the field of computer science\",\n",
    "                         \"tell me the singular form\",\n",
    "                         \"more examples\",\n",
    "                         \"what are the available parts of speech\"]\n",
    "\n",
    "print_parse(grammar_2, filter_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related intent\n",
    "\n",
    "- What are possible synonyms?\n",
    "- What are its opposites?\n",
    "- What are related words? (generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_derived = [\n",
    "    Rule('$ROOT', '$RelatedQuery', lambda sems: merge_dicts({'intent': 'related'}, sems[0])),\n",
    "    \n",
    "    Rule('$RelatedQuery', '?$ShowVerb $RelatedQueryElements', sems_1),\n",
    "    # What are related senses?\n",
    "    Rule('$RelatedQuery', 'what $Be $RelatedQueryElements', sems_2),\n",
    "    Rule('$RelatedQuery', 'which $Be $RelatedQueryElements', sems_2),\n",
    "    # What senses are related\n",
    "    Rule('$RelatedQuery', 'what $Word $Be $RelatedQueryElements', lambda sems: sems[3]),\n",
    "    Rule('$RelatedQuery', '$RelatedQueryElements', sems_0),\n",
    "    Rule('$RelatedQueryElements', '?$Determiner $Derived ?$Word', sems_1),\n",
    "    Rule('$RelatedQueryElements', '?$More $Derived ?$Word', sems_1),\n",
    "    Rule('$RelatedQueryElements', '?$Determiner $Quality $Derived', lambda sems: merge_dicts(sems[1], sems[2])),\n",
    "    Rule('$RelatedQueryElements', '?$More $Quality $Derived', lambda sems: merge_dicts(sems[1], sems[2])),\n",
    "    \n",
    "    \n",
    "     # some examples of the derived words\n",
    "    Rule('$RelatedQueryElements', '?$More $Extra $StopWord ?$Determiner $Derived ?$Word',\n",
    "         lambda sems: merge_dicts(sems[1], sems[4])),\n",
    "         \n",
    "    Rule('$Derived', 'derived', {'filtertype': 'derived'}),\n",
    "    Rule('$Derived', 'synonym', {'filtertype': 'synonym'}),\n",
    "    Rule('$Derived', 'synonyms', {'filtertype': 'synonym'}),\n",
    "    Rule('$Derived', 'antonym', {'filtertype': 'antonym'}),\n",
    "    Rule('$Derived', 'opposites', {'filtertype': 'antonym'}),\n",
    "    Rule('$Derived', 'antonyms', {'filtertype': 'antonym'}),\n",
    "    Rule('$Derived', 'related', {'filtertype': 'related'}),\n",
    "    \n",
    "    Rule('$Quality', '$UnquotedToken', lambda sems: {'category': sems[0]}),\n",
    "]\n",
    "\n",
    "rules_words = [\n",
    "    Rule('$Word', 'word'),\n",
    "    Rule('$Word', 'words'),\n",
    "    Rule('$Word', 'lexeme'),\n",
    "    Rule('$Word', 'lexemes'),\n",
    "    Rule('$Word', 'lemma'),\n",
    "    Rule('$Word', 'lemmas'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 104 rules.\n"
     ]
    }
   ],
   "source": [
    "rules_3 = rules_be + rules_definition + rules_determiner + rules_filter + rules_words + rules_wordsenses + rules_derived\n",
    "\n",
    "\n",
    "grammar_3 = Grammar(rules=rules_3, annotators=annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "For the utterance what are derived words:\n",
      "{'intent': 'related', 'filtertype': 'derived'}\n",
      "{'intent': 'related', 'filtertype': 'derived'}\n",
      "{'intent': 'define', 'np': 'derived words'}\n",
      "====================\n",
      "For the utterance what are possible derived words:\n",
      "{'intent': 'related', 'filtertype': 'derived'}\n",
      "{'intent': 'define', 'np': 'possible derived words'}\n",
      "====================\n",
      "For the utterance show me some antonyms:\n",
      "{'intent': 'related', 'filtertype': 'antonym'}\n",
      "{'intent': 'related', 'filtertype': 'antonym'}\n",
      "{'intent': 'related', 'category': 'some', 'filtertype': 'antonym'}\n",
      "{'intent': 'related', 'category': 'some', 'filtertype': 'antonym'}\n",
      "{'intent': 'define', 'np': 'some antonyms'}\n",
      "{'intent': 'define', 'np': 'antonyms'}\n",
      "====================\n",
      "For the utterance show me some stylish synonyms:\n",
      "{'intent': 'related', 'category': 'stylish', 'filtertype': 'synonym'}\n",
      "{'intent': 'related', 'category': 'stylish', 'filtertype': 'synonym'}\n",
      "{'intent': 'define', 'np': 'some stylish synonyms'}\n",
      "{'intent': 'define', 'np': 'stylish synonyms'}\n",
      "====================\n",
      "For the utterance what are some opposites:\n",
      "{'intent': 'related', 'filtertype': 'antonym'}\n",
      "{'intent': 'related', 'filtertype': 'antonym'}\n",
      "{'intent': 'related', 'category': 'some', 'filtertype': 'antonym'}\n",
      "{'intent': 'related', 'category': 'some', 'filtertype': 'antonym'}\n",
      "{'intent': 'define', 'np': 'some opposites'}\n",
      "{'intent': 'define', 'np': 'opposites'}\n"
     ]
    }
   ],
   "source": [
    "related_utterances = [\"what are derived words\", \"what are possible derived words\",\n",
    "                          \"show me some antonyms\", \"show me some stylish synonyms\",\n",
    "                          \"what are some opposites\"]\n",
    "\n",
    "print_parse(grammar_3, related_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide queries\n",
    "\n",
    "- is it regular?\n",
    "- is family a synonym for collection?\n",
    "- can adverbs have a comparative form?\n",
    "- can it be used as a noun\n",
    "- do nouns have comparatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_decide = [\n",
    "    Rule('$ROOT', '$DecideQuery',\n",
    "         lambda sems: merge_dicts({'intent': 'decide'}, sems[0])),\n",
    "    \n",
    "    # is it a noun?\n",
    "    Rule('$DecideQuery', '$Be $DecideQuerySubject ?$Determiner $DecideQueryObject',\n",
    "        merge_dicts_singleparam),\n",
    "    \n",
    "    Rule('$DecideQuery', 'can $DecideQuerySubject $Be ?$Determiner $DecideQueryObject',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    # can reticence be used as a noun\n",
    "    Rule('$DecideQuery', 'can $DecideQuerySubject ?$Be $UsedLike $DecideQueryObject',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    Rule('$DecideQuery', 'can $DecideQuerySubject $Have ?$Determiner $DecideQueryObject',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    Rule('$DecideQuery', '$Do $DecideQuerySubject $Have ?$Determiner $DecideQueryObject',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    \n",
    "    # do adverbs have comparatives?\n",
    "    Rule('$DecideQuery', '$Do $DecideQuerySubject $Have $DecideQueryObject',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    \n",
    "    Rule('$DecideQuerySubject', \"it\"),\n",
    "    Rule('$DecideQuerySubject', \"$POS\",\n",
    "         lambda sems: {\"filtertype\": \"grammatical\", \"requiredPos\": sems[0]}),\n",
    "    \n",
    "    # \"is family a noun?\"\n",
    "    Rule('$DecideQuerySubject', \"$NounPhrase\", sems_0),\n",
    "    \n",
    "    # is it a noun\n",
    "    Rule('$DecideQueryObject', \"$POS\",\n",
    "         lambda sems: {'filtertype': 'grammatical', 'requiredPos': sems[0]}),\n",
    "    \n",
    "    # is it a comparative\n",
    "    Rule('$DecideQueryObject', \"$GrammaticalFeature ?$FormStopword\",\n",
    "         lambda sems: {'filtertype': 'grammatical', 'grammaticalFeature': sems[0]}),\n",
    "    \n",
    "    # does it have opposites?\n",
    "    Rule('$DecideQueryObject', \"$Derived\", sems_0),\n",
    "    \n",
    "    # does it have examples\n",
    "    Rule('$DecideQueryObject', \"$Extra\", sems_0),\n",
    "    \n",
    "    # is it a synonym of love?\n",
    "    Rule('$DecideQueryObject', \"$Derived $StopWord $NounPhrase\",\n",
    "         lambda sems: merge_dicts(sems[0], {'relatedTerm': sems[2]['np']})),\n",
    "    \n",
    "    # examples, usages, senses...\n",
    "    Rule('$DecideQueryObject', '$Extra', sems_0),\n",
    "    \n",
    "    Rule('$UsedLike', 'used as ?in ?$Determiner'),\n",
    "    Rule('$UsedLike', 'used like ?in ?$Determiner'),\n",
    "    Rule('$UsedLike', 'adopted ?in ?$Determiner'),\n",
    "    \n",
    "    Rule('$FormStopWord', \"?morphological form\"),\n",
    "    Rule('$FormStopWord', \"morphology\"),\n",
    "]\n",
    "\n",
    "rules_have = [\n",
    "    Rule(\"$Have\", 'have'),\n",
    "    Rule(\"$Have\", 'has'),\n",
    "    Rule(\"$Have\", 'had'),\n",
    "    Rule(\"$Have\", 'having'),\n",
    "    Rule(\"$Have\", \"' d\")\n",
    "]\n",
    "\n",
    "rules_do = [\n",
    "    Rule(\"$Do\", 'do'),\n",
    "    Rule(\"$Do\", 'does'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 132 rules.\n"
     ]
    }
   ],
   "source": [
    "rules_4 = rules_be + rules_have + rules_do + rules_definition + \\\n",
    "            rules_determiner + rules_filter + rules_words + rules_wordsenses + \\\n",
    "            rules_derived + rules_decide\n",
    "\n",
    "\n",
    "grammar_4 = Grammar(rules=rules_4, annotators=annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "For the utterance is it singular:\n",
      "{'intent': 'decide', 'filtertype': 'grammatical', 'grammaticalFeature': 'singular'}\n",
      "{'intent': 'decide', 'np': 'it', 'filtertype': 'grammatical', 'grammaticalFeature': 'singular'}\n",
      "====================\n",
      "For the utterance is family a synonym of collection:\n",
      "{'intent': 'decide', 'np': 'family', 'filtertype': 'synonym', 'relatedTerm': 'collection'}\n",
      "{'intent': 'decide', 'np': 'family a', 'filtertype': 'synonym', 'relatedTerm': 'collection'}\n",
      "====================\n",
      "For the utterance can adverbs have tense:\n",
      "{'intent': 'decide', 'filtertype': 'grammatical', 'requiredPos': 'adverb', 'grammaticalFeature': 'tense'}\n",
      "{'intent': 'decide', 'np': 'adverbs', 'filtertype': 'grammatical', 'grammaticalFeature': 'tense'}\n",
      "====================\n",
      "For the utterance can it be used as a noun:\n",
      "{'intent': 'decide', 'filtertype': 'grammatical', 'requiredPos': 'noun'}\n",
      "{'intent': 'decide', 'np': 'it', 'filtertype': 'grammatical', 'requiredPos': 'noun'}\n",
      "{'intent': 'decide', 'np': 'it be', 'filtertype': 'grammatical', 'requiredPos': 'noun'}\n",
      "====================\n",
      "For the utterance do nouns have tense:\n",
      "{'intent': 'decide', 'filtertype': 'grammatical', 'requiredPos': 'noun', 'grammaticalFeature': 'tense'}\n",
      "{'intent': 'decide', 'filtertype': 'grammatical', 'requiredPos': 'noun', 'grammaticalFeature': 'tense'}\n",
      "{'intent': 'decide', 'np': 'nouns', 'filtertype': 'grammatical', 'grammaticalFeature': 'tense'}\n",
      "{'intent': 'decide', 'np': 'nouns', 'filtertype': 'grammatical', 'grammaticalFeature': 'tense'}\n"
     ]
    }
   ],
   "source": [
    "decision_utterances = [\"is it singular\", \"is family a synonym of collection\",\n",
    "                           \"can adverbs have tense\", \"can it be used as a noun\",\n",
    "                            \"do nouns have tense\"]\n",
    "\n",
    "print_parse(grammar_4, decision_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: Question Answering demo\n",
    "\n",
    "By now we'll ignore that a parsed sentence may (and usually does) bring about multiple semantics.\n",
    "\n",
    "Instead, we'll hardcode a \"simple\" priority choice: take the semantics with the greatest number of keys. It should work in a number of situations.\n",
    "\n",
    "In case the choices are only definitions, pick the one with the shortest np.\n",
    "\n",
    "In case I have to choose between two filters, always prefer the number type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.providers import WiktionaryProvider\n",
    "from tools.answering import QuestionAnsweringContext, DefinitionIntent, FilterIntent\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "provider = WiktionaryProvider()\n",
    "\n",
    "def priority_calculator(parse):\n",
    "    filtertype_priority = {'grammatical': 1, 'semantic': 2, 'number': 3,\n",
    "                  'synonym': 4, 'antonym': 4, 'derived': 4, 'related': 4}\n",
    "    \n",
    "    # the more keys, the better\n",
    "    score = len(parse.keys()) * 10 + (filtertype_priority[parse['filtertype']] if 'filtertype' in parse else 0)\n",
    "    \n",
    "    # ... except for np\n",
    "    score -=  12 * len(parse['np'].split(\" \")) if 'np' in parse else 0\n",
    "    return score\n",
    "    \n",
    "def pick_best_semantics(parses):\n",
    "    \"\"\"\n",
    "    Return the most likely matching parse.\n",
    "    \n",
    "    This is a simple stub. Does not do any ML here, despite it could\n",
    "    (and should), so use with care.\n",
    "    \"\"\"\n",
    "    if parses == []:\n",
    "        return {}\n",
    "    semantics = [parse.semantics for parse in parses]\n",
    "    \n",
    "    if all(parse[\"intent\"] == \"define\" for parse in semantics):\n",
    "        picked_parser = min(semantics, key=lambda parse: len(parse[\"np\"]))\n",
    "    \n",
    "    else:\n",
    "        picked_parser = max(semantics, key=priority_calculator)\n",
    "        \n",
    "    return picked_parser\n",
    "\n",
    "context = QuestionAnsweringContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'related', 'filtertype': 'synonym'}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_4.parse_input(\"show me synonyms\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'related', 'filtertype': 'antonym'}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_4.parse_input(\"show me antonyms\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'decide', 'filtertype': 'grammatical', 'requiredPos': 'adjective'}, {'intent': 'decide', 'np': 'it', 'filtertype': 'grammatical', 'requiredPos': 'adjective'}, {'intent': 'decide', 'np': 'it be', 'filtertype': 'grammatical', 'requiredPos': 'adjective'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': 'decide', 'filtertype': 'grammatical', 'requiredPos': 'adjective'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_4.parse_input(\"can it be used as an adjective\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first', 'variant': 'example'}, {'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('what about more examples for the first one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'filter', 'variant': 'example'}, {'intent': 'definition', 'np': 'some examples'}, {'intent': 'definition', 'np': 'examples'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter', 'variant': 'example'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('show me some examples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'filter', 'filtertype': 'semantic', 'value': 'botanics', 'variant': 'example'}, {'intent': 'filter', 'filtertype': 'semantic', 'value': 'botanics', 'variant': 'example'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter',\n",
       " 'filtertype': 'semantic',\n",
       " 'value': 'botanics',\n",
       " 'variant': 'example'}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('more examples for the botanics one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first', 'variant': 'example'}, {'intent': 'filter', 'filtertype': 'semantic', 'value': 'first', 'variant': 'example'}, {'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}, {'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('more examples for the first one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first', 'variant': 'example'}, {'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}, {'intent': 'definition', 'np': 'more examples for the first one'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('show me more examples for the first one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'define', 'np': 'butterfly'}"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('define butterfly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with wrap_open(\"intents/sample.json\") as fp:\n",
    "    dataset = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import copy\n",
    "\n",
    "class SamplePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X=None, Y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, dataset):\n",
    "        # simply return sessions as an array\n",
    "        df = copy.deepcopy(dataset)\n",
    "        sessions = df['sessions']\n",
    "        for session in sessions:\n",
    "            for turn in session['turns']:\n",
    "                del turn['target']\n",
    "            session['turns'] = [turn['utterance'] for turn in session['turns']]\n",
    "        return sessions\n",
    "\n",
    "sessions = SamplePreprocessor().fit_transform(dataset)\n",
    "targets = [[turn['target'] for turn in session['turns']] for session in dataset['sessions']]\n",
    "flattened_utterances = [[turn['utterance'] for turn in session['turns']] for session in dataset['sessions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarMatcher(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"This class serves as an evaluation framework for an intent classifier\"\"\"\n",
    "    def __init__(self, grammar: Grammar):\n",
    "        self.grammar = grammar\n",
    "\n",
    "    def fit(self, sessions=None, targets=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, sessions):\n",
    "        \"\"\"\n",
    "        Convert the given sessions to intents.\n",
    "        Sessions is expected to be the output of SampleProcessor.\n",
    "        \"\"\"\n",
    "        targets = []\n",
    "        for session in sessions:\n",
    "            answers = []\n",
    "            \n",
    "            for utterance in session['turns']:\n",
    "                utterance = utterance.strip().lower()\n",
    "                utterance = utterance.replace(\"'\", '\"')\n",
    "\n",
    "                for eos in [\".\", \"?\", \"!\"]:\n",
    "                    utterance = remove_suffix(utterance, eos)\n",
    "\n",
    "                answers.append(self.grammar.parse_input(utterance))\n",
    "            targets.append(answers)\n",
    "        return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "class GreedyMatcher(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, sessions=None, target=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, sessions):\n",
    "        target = []\n",
    "        for session in sessions:\n",
    "            turns = []\n",
    "            for parses in session:\n",
    "                try:\n",
    "                    turns.append(pick_best_semantics(parses))\n",
    "                except:\n",
    "                    traceback.print_exception() \n",
    "                    turns.append({})\n",
    "            target.append(turns)\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_matcher = Pipeline([('preprocessor', SamplePreprocessor()),\n",
    "                                ('grammar_matcher', GrammarMatcher(grammar_4)),\n",
    "                                ('picker', GreedyMatcher())])\n",
    "\n",
    "greedy_matcher.fit(dataset, targets)\n",
    "output = greedy_matcher.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show me all meanings for 'desire' {'intent': 'define', 'np': 'desire', 'quantifier': 'all'} {}\n",
      "===\n",
      "show me all examples for stashes {'intent': 'define', 'np': 'stashes', 'all': True, 'variant': 'example'} {'intent': 'define', 'np': 'all examples for stashes'}\n",
      "===\n",
      "show me examples as a noun {'intent': 'filter', 'filtertype': 'grammatical', 'required_pos': 'noun', 'variant': 'example'} {'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'noun', 'variant': 'example'}\n",
      "===\n",
      "Compare with house {'intent': 'compare', 'comparisonTerm': 'house'} {}\n",
      "===\n",
      "What are stilish synonyms? {'intent': 'related', 'filtertype': 'synonym', 'category': 'stylish', 'variant': 'example'} {'intent': 'related', 'category': 'stilish', 'filtertype': 'synonym'}\n",
      "===\n",
      "What are derived words? {'intent': 'related', 'filtertype': 'derived', 'category': 'formal|researched|stylish', 'variant': 'example'} {'intent': 'related', 'filtertype': 'derived'}\n",
      "===\n",
      "In the field of biology, does it have special meanings? {'intent': 'filter', 'filtertype': 'semantic', 'category': 'biology'} {}\n",
      "===\n",
      "Tell me about run {'intent': 'define', 'np': 'run'} {'intent': 'define', 'np': 'about run'}\n",
      "===\n",
      "Show me usages of the past simple tense {'intent': 'filter', 'filtertype': 'grammatical', 'grammaticalForm': 'past simple tense', 'variant': 'example'} {'intent': 'define', 'np': 'usages of the past simple tense'}\n",
      "===\n",
      "Show me phrasal verbs built with it, along with examples {'intent': 'filter', 'filtertype': 'semantic', 'grammaticalForm': 'phrasal verb', 'variant': 'example'} {}\n",
      "===\n",
      "Which parts of speech are available for it? {'intent': 'filter', 'filtertype': 'grammatical', 'variant': 'pos'} {}\n",
      "===\n",
      "What are its grammatical quirks? {'intent': 'filter', 'filtertype': 'grammatical', 'grammaticalFeature': 'irregular'} {'intent': 'define', 'np': 'grammatical quirks'}\n",
      "===\n",
      "In Computer Science, what does one run? {'intent': 'filter', 'filtertype': 'semantic', 'category': 'computer science'} {}\n",
      "===\n",
      "Who is Apollo? {'intent': 'define', 'np': 'Apollo', 'isPerson': True} {'intent': 'define', 'isPerson': True, 'np': 'apollo'}\n",
      "===\n",
      "What is Apollo? {'intent': 'define', 'np': 'Apollo'} {'intent': 'define', 'np': 'apollo'}\n",
      "===\n",
      "Can it be used as an adjective? {'intent': 'decide', 'filtertype': 'semantic', 'requiredPos': 'adjective'} {'intent': 'decide', 'filtertype': 'grammatical', 'requiredPos': 'adjective'}\n",
      "===\n",
      "Which language does it come from? {'intent': 'filter', 'filtertype': 'etymology'} {}\n",
      "===\n",
      "Is Apollo an animal? {'intent': 'filter', 'filtertype': 'semantic', 'category': 'animal'} {}\n",
      "===\n",
      "comparative and superlative {'intent': 'filter', 'filtertype': 'grammatical', 'grammaticalFeature': 'comparative|superlative'} {}\n",
      "===\n",
      "Is it regular? {'intent': 'decision', 'filtertype': 'grammatical', 'grammaticalFeature': 'regular'} {}\n",
      "===\n",
      "Provide some examples {'intent': 'filter', 'variant': 'example'} {}\n",
      "===\n",
      "What are the antonyms? {'intent': 'filter', 'filtertype': 'antonym'} {'intent': 'related', 'category': 'the', 'filtertype': 'antonym'}\n",
      "===\n",
      "Tell me more about the dynasty version {'intent': 'filter', 'filtertype': 'semantic', 'value': 'dinasty'} {'intent': 'define', 'np': 'more about the dynasty version'}\n",
      "===\n",
      "What is the plural of family? {'intent': 'filter', 'filtertype': 'grammatical', 'grammaticalFeature': 'plural'} {'intent': 'define', 'np': 'plural of family'}\n",
      "===\n",
      "tell me about the mathematics sense {'intent': 'filter', 'filtertype': 'semantic', 'value': 'mathematics'} {'intent': 'define', 'np': 'mathematics sense'}\n",
      "===\n",
      "What is the comparative form of 'terrestrial'? {'intent': 'filter', 'np': 'terrestrial', 'filtertype': 'grammatical', 'grammaticalFeature': 'comparative'} {}\n",
      "===\n",
      "What is the difference between the comparative and superlative? {'intent': 'compare', 'comparisonTerm': 'comparative', 'comparisonTerm2': 'superlative'} {'intent': 'define', 'np': 'difference between the comparative and superlative'}\n",
      "===\n",
      "Can adverbs have a comparative form? {'intent': 'decision', 'requiredPos': 'adverb', 'grammaticalFeature': 'comparative'} {}\n",
      "===\n",
      "Show me an irregular adverb {'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'adverb', 'grammaticalFeature': 'irregular'} {'intent': 'define', 'np': 'irregular adverb'}\n",
      "===\n",
      "Do nouns have comparatives? {'intent': 'decision', 'requiredPos': 'noun', 'grammaticalFeature': 'comparative'} {}\n",
      "===\n",
      "What are the parts of speech available in English? {'intent': 'filter', 'filtertype': 'grammatical', 'variant': 'pos'} {'intent': 'define', 'np': 'parts of speech available in english'}\n",
      "===\n",
      "Give me an example with 'break' {'intent': 'define', 'np': 'break', 'variant': 'example'} {}\n",
      "===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5395480225988701"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A bunch of evaluation functions\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# \"perfect\" scorers, because they check whether two values are equal\n",
    "def perfect_accuracy(y_truth, y_pred, debug_x=None):\n",
    "    # Concatenate lists-of-lists into flattened lists.\n",
    "    # Not the most efficient, but I find it very neat\n",
    "    y_truth = sum(y_truth, [])\n",
    "    y_pred = sum(y_pred, [])\n",
    "    utterances = sum(debug_x, []) if debug_x else None\n",
    "    \n",
    "    score = []\n",
    "    for idx, (y_t, y_p) in enumerate(zip(y_truth, y_pred)):\n",
    "        matched_items = len(set(y_t.items()) & set(y_p.items()))\n",
    "        if len(y_t) == 0:\n",
    "            score.append(1.0 if len(y_t.items()) == 0 else 0.0)\n",
    "        else:\n",
    "            score.append(matched_items / len(y_t))\n",
    "        if debug_x and score[-1] < 1.0:\n",
    "            print(utterances[idx], y_t, y_p)\n",
    "            print(\"===\")\n",
    "        \n",
    "    return np.average(score)\n",
    "\n",
    "def intent_match_score(y_truth, y_pred):\n",
    "    y_pred = [intent['intent'] if len(intent) else '' for intent in sum(y_pred, [])]\n",
    "    y_truth = [intent['intent'] if len(intent) else '' for intent in sum(y_truth, [])]\n",
    "    \n",
    "    return precision_recall_fscore_support(y_truth, y_pred)\n",
    "\n",
    "perfect_accuracy(targets, output, debug_x=flattened_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'definition', 'np': 'butterfly'}\n",
      "Current state of the entities:  <tools.answering.DefinitionEntity object at 0x7efc2b793a90>\n",
      "Serializing an answer here...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Found the following meanings<ul></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(grammar_2, \"define butterfly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'type': 'number', 'value': 2}\n",
      "Current state of the entities:  <tools.answering.DefinitionEntity object at 0x7efc2b793a90>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (1,1, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-55b77863b421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"more about the second one\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-a7d6fadd9b6e>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(grammar, question)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbest_semantics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'filter'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbest_semantics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'number'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_intent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFilterIntent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'single'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_semantics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# ???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/knowledge-glue/notebooks/tools/answering.py\u001b[0m in \u001b[0;36mhandle_intent\u001b[0;34m(self, intent)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mmax_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msenses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfailed_intent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"This sense does not exist! Try asking me to fetch the {randint(1, max_range)})°\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                     \u001b[0msense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msenses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"More details on the item no. {number}: <br>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (1,1, 0)"
     ]
    }
   ],
   "source": [
    "answer_question(grammar_2, \"more about the second one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 0.23.1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: None\n",
      "Author-email: None\n",
      "License: new BSD\n",
      "Location: /usr/local/lib/python3.7/dist-packages\n",
      "Requires: scipy, numpy, threadpoolctl, joblib\n",
      "Required-by: sklearn, sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "!pip3 show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
