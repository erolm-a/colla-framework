{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sippycup semantic parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('3rdparty/sippycup')\n",
    "from annotator import *\n",
    "from parsing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rule(grammar, rule):\n",
    "    if contains_optionals(rule):\n",
    "        add_rule_containing_optional(grammar, rule)\n",
    "    elif is_lexical(rule):\n",
    "        grammar.lexical_rules[rule.rhs].append(rule)\n",
    "    elif is_unary(rule):\n",
    "        grammar.unary_rules[rule.rhs].append(rule)\n",
    "    elif is_binary(rule):\n",
    "        grammar.binary_rules[rule.rhs].append(rule)\n",
    "    elif all([is_cat(rhsi) for rhsi in rule.rhs]):\n",
    "        add_n_ary_rule(grammar, rule)\n",
    "    else:\n",
    "        make_cat(grammar, rule)\n",
    "        # raise Exception('RHS mixes terminals and non-terminals: %s' % rule\n",
    "\n",
    "def add_rule_containing_optional(grammar, rule):\n",
    "    # Find index of the first optional element on the RHS.\n",
    "    first = next((idx for idx, elt in enumerate(rule.rhs) if is_optional(elt)), -1)\n",
    "    assert first >= 0\n",
    "    assert len(rule.rhs) > 1, 'Entire RHS is optional: %s' % rule\n",
    "    prefix = rule.rhs[:first]\n",
    "    suffix = rule.rhs[(first + 1):]\n",
    "    # First variant: the first optional element gets deoptionalized.\n",
    "    deoptionalized = (rule.rhs[first][1:],)\n",
    "    add_rule(grammar, Rule(rule.lhs, prefix + deoptionalized + suffix, rule.sem))\n",
    "    # Second variant: the first optional element gets removed.\n",
    "    # If the semantics is a value, just keep it as is.\n",
    "    sem = rule.sem\n",
    "    # But if it's a function, we need to supply a dummy argument for the removed element.\n",
    "    if isinstance(rule.sem, FunctionType):\n",
    "        sem = lambda sems: rule.sem(sems[:first] + [None] + sems[first:])\n",
    "    add_rule(grammar, Rule(rule.lhs, prefix + suffix, sem))\n",
    "\n",
    "def make_cat(grammar, rule):\n",
    "    \"\"\"\n",
    "    Convert a terminal in the RHS into a non-terminal.\n",
    "    \n",
    "    Conversion works by creating a nonterminal from each terminal if\n",
    "    it does not exist already in the grammar, otherwise it just replaces it.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_rhs = []\n",
    "    for rhsi in rule.rhs:\n",
    "        if is_cat(rhsi):\n",
    "            cat_name = rhsi\n",
    "        else:\n",
    "            cat_name = \"$\" + rhsi + \"__nonterminal\"\n",
    "            if cat_name not in grammar.categories:\n",
    "                grammar.categories.add(cat_name)\n",
    "                # print(f\"Adding rule: {cat_name} := {str(rhsi)}\")\n",
    "                add_rule(grammar, Rule(cat_name, rhsi))\n",
    "        new_rhs.append(cat_name)\n",
    "        # print(f\"Adding rule: {rule.lhs} := {str(new_rhs)}\")\n",
    "    add_rule(grammar, Rule(rule.lhs, tuple(new_rhs), rule.sem))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(grammar, input):\n",
    "    \"\"\"Returns a list of all parses for input using grammar.\"\"\"\n",
    "    tokens_spacy = nlp(input) # New\n",
    "    tokens = [token.text for token in tokens_spacy]\n",
    "    chart = defaultdict(list)\n",
    "    for j in range(1, len(tokens) + 1):\n",
    "        for i in range(j - 1, -1, -1):\n",
    "            apply_annotators(grammar, chart, tokens, i, j)\n",
    "            apply_lexical_rules(grammar, chart, tokens, i, j)\n",
    "            apply_binary_rules(grammar, chart, i, j)\n",
    "            apply_unary_rules(grammar, chart, i, j)\n",
    "    parses = chart[(0, len(tokens))]\n",
    "    if hasattr(grammar, 'start_symbol') and grammar.start_symbol:\n",
    "        parses = [parse for parse in parses if parse.rule.lhs == grammar.start_symbol]\n",
    "    return parses\n",
    "\n",
    "class Grammar:\n",
    "    def __init__(self, rules=[], annotators=[], start_symbol='$ROOT'):\n",
    "        self.categories = set()\n",
    "        self.lexical_rules = defaultdict(list)\n",
    "        self.unary_rules = defaultdict(list)\n",
    "        self.binary_rules = defaultdict(list)\n",
    "        self.annotators = annotators\n",
    "        self.start_symbol = start_symbol\n",
    "        for rule in rules:\n",
    "            add_rule(self, rule)\n",
    "        print('Created grammar with %d rules.' % len(rules))\n",
    "\n",
    "    def parse_input(self, input):\n",
    "        \"\"\"Returns a list of parses for the given input.\"\"\"\n",
    "        return parse_input(self, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$Number', 16)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumberAnnotator().annotate(['16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$Token', 'foo')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenAnnotator().annotate(['foo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWordAnnotator(Annotator):\n",
    "    \"\"\"Let spacy detect stop words for us\"\"\"\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) == 1:\n",
    "            if nlp(tokens[0])[0].is_stop:\n",
    "                return [('$StopWord', tokens[0])]\n",
    "        return []\n",
    "\n",
    "class ShowVerbAnnotator(Annotator):\n",
    "    def __init__(self, threshold = 0.7):\n",
    "        self.show_verbs = [(\"define\", \"\"), (\"tell\", \"me\"), (\"show\", \"me\")]\n",
    "        self.spacy_show_toks = nlp(\" \".join([verb for verb, _ in self.show_verbs]))\n",
    "        self.threshold = 0.7\n",
    "\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) <= 2:\n",
    "            spacy_tokens = nlp(\" \".join(tokens))\n",
    "            spacy_token = spacy_tokens[0]\n",
    "            if spacy_token.pos_ != 'VERB':\n",
    "                return []\n",
    "            \n",
    "            # If the verb matches in meaning and, in case it requires a\n",
    "            # follow-up word, that this matches as well, then it's a match.\n",
    "            for idx, (verb, acc) in enumerate(self.show_verbs):\n",
    "                spacy_verb = self.spacy_show_toks[idx]\n",
    "                if spacy_token.similarity(spacy_verb) >= self.threshold:\n",
    "                    if verb == tokens[0] and acc != \"\" and (len(tokens) == 1 or tokens[1] != acc):\n",
    "                        return []\n",
    "                    return [('$ShowVerb', tokens)]\n",
    "        return []\n",
    "\n",
    "    \n",
    "class TokenAnnotatorBuilder(Annotator):\n",
    "    def __init__(self, category_name, excluded):\n",
    "        Annotator.__init__(self)\n",
    "        self.category_name = category_name\n",
    "        self.excluded = excluded\n",
    "    \n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) == 1:\n",
    "            token = tokens[0]\n",
    "            if token not in self.excluded:\n",
    "                return [(self.category_name, token)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['say'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['say'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['define'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['define'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['tell', 'me'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['tell', 'me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TokenWithoutQuotes', 'Jeff')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenAnnotatorBuilder('TokenWithoutQuotes', ['\"', '\"']).annotate(['Jeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CELL_CAPACITY = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar definition\n",
    "\n",
    "We will model the queries after a few intents:\n",
    "\n",
    "- Definition: asking for a definition of a noun phrase\n",
    "- Comparison: compare two noun phrases\n",
    "- Filtering/Details on a given sense: ask for further details on a previously mentioned sense\n",
    "- Usage of form\n",
    "- General grammar knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def sems_0(sems):\n",
    "    return sems[0]\n",
    "\n",
    "def sems_1(sems):\n",
    "    return sems[1]\n",
    "\n",
    "def sems_2(sems):\n",
    "    return sems[2]\n",
    "\n",
    "def merge_dicts(d1, d2):\n",
    "    if not d2:\n",
    "        return d1\n",
    "    if not d1:\n",
    "        return {}\n",
    "    return {**d1, **d2}\n",
    "\n",
    "def strip_none(sems):\n",
    "    return [sem for sem in sems if sem]\n",
    "\n",
    "def merge_dicts_singleparam(sems):\n",
    "    if all([sem is None for sem in sems]):\n",
    "        return {}\n",
    "    return reduce(merge_dicts, strip_none(sems))\n",
    "\n",
    "def to_np(sems):\n",
    "    return {'np': strip_none(sems)[0]}\n",
    "\n",
    "def concatenate(sems):\n",
    "    return \" \".join(strip_none(sems))\n",
    "\n",
    "\n",
    "rules_definition = [\n",
    "    Rule('$ROOT', '$DefinitionQuery', sems_0),\n",
    "    Rule('$DefinitionQuery', '$DefinitionQueryElements',\n",
    "         lambda sems: merge_dicts({'intent': 'definition'}, sems[0])),\n",
    "    Rule('$DefinitionQueryElements', '$DefinitionQuestion $NounPhrase',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    # Special case: \"what does X mean?\"\n",
    "    Rule('$DefinitionQueryElements', 'what does $NounPhrase mean', sems_2),\n",
    "    \n",
    "    Rule('$DefinitionQuestion', '$ShowVerb ?me'),\n",
    "    Rule('$DefinitionQuestion', '$WhatDefinition'),\n",
    "    Rule('$DefinitionQuestion', '$WhoDefinition', {'is_person': True}),\n",
    "    Rule('$WhoDefinition', 'who $Be'),\n",
    "    Rule('$WhatDefinition', 'what $Be ?$Determiner ?$DefinitionFor'),\n",
    "    Rule('$WhatDefinition', 'how do you $ShowVerb'),\n",
    "    Rule('$DefinitionFor', 'meaning $StopWord'),\n",
    "    Rule('$DefinitionFor', 'sense $StopWord'),\n",
    "    Rule('$DefinitionFor', 'definition $StopWord'),\n",
    "    Rule('$NounPhrase', \"$Tokens\", to_np),\n",
    "    Rule('$NounPhrase', \"' $Tokens '\", to_np),\n",
    "    Rule('$NounPhrase', '\" $Tokens \"', to_np),\n",
    "    Rule('$Tokens', '$UnquotedToken ?$Tokens', concatenate)\n",
    "]\n",
    "\n",
    "rules_determiner = [\n",
    "    Rule('$Determiner', 'a'),\n",
    "    Rule('$Determiner', 'an'),\n",
    "    Rule('$Determiner', 'the'),\n",
    "    Rule('$Determiner', 'its'),\n",
    "]\n",
    "\n",
    "rules_be = [\n",
    "    Rule(\"$Be\", \"is\"),\n",
    "    Rule(\"$Be\", \"are\"),\n",
    "    Rule(\"$Be\", \"'s\"),\n",
    "    Rule(\"$Be\", \"were\"),\n",
    "    Rule(\"$Be\", \"was\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 25 rules.\n"
     ]
    }
   ],
   "source": [
    "annotators = [StopWordAnnotator(), ShowVerbAnnotator(), TokenAnnotatorBuilder(\"$UnquotedToken\", [\"'\", '\"', \"?\"])]\n",
    "rules = rules_definition + rules_determiner + rules_be\n",
    "grammar = Grammar(rules=rules, annotators=annotators)\n",
    "parses = grammar.parse_input('define pi')\n",
    "parse = parses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'pi'}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse.semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input('define \"pi\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'is_person': True, 'np': 'apollo'}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.parse_input('who is apollo')[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'pi'}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $ROOT ('$DefinitionQuery',)\n",
      "|\n",
      "-- $DefinitionQuery ('$DefinitionQueryElements',)\n",
      "|\n",
      "---- $DefinitionQueryElements ('$DefinitionQuestion', '$NounPhrase')\n",
      "|\n",
      "------ $DefinitionQuestion ('$ShowVerb',)\n",
      "|\n",
      "-------- $ShowVerb ('define',)\n",
      "|\n",
      "------ $NounPhrase ('$\"__nonterminal', '$NounPhrase_$\"__nonterminal')\n",
      "|\n",
      "-------- $\"__nonterminal ('\"',)\n",
      "|\n",
      "-------- $NounPhrase_$\"__nonterminal ('$Tokens', '$\"__nonterminal')\n",
      "|\n",
      "---------- $Tokens ('$UnquotedToken',)\n",
      "|\n",
      "------------ $UnquotedToken ('pi',)\n",
      "|\n",
      "---------- $\"__nonterminal ('\"',)\n"
     ]
    }
   ],
   "source": [
    "def pretty_print(parse, depth=0):\n",
    "    if not isinstance(parse, str):\n",
    "        if depth > 0:\n",
    "            for _ in range(1):\n",
    "                print(\"|\")\n",
    "        print(\"-\" * depth * 2, parse.rule.lhs, parse.rule.rhs)\n",
    "        for child in parse.children:\n",
    "            pretty_print(child, depth+1)\n",
    "\n",
    "pretty_print(parses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input(\"define 'pi'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input(\"tell me the life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'the life'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input(\"what is an 'apple'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'apple'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'definition', 'np': 'the definition of botanics'}\n",
      "{'intent': 'definition', 'np': 'definition of botanics'}\n",
      "{'intent': 'definition', 'np': 'botanics'}\n"
     ]
    }
   ],
   "source": [
    "parses = grammar.parse_input(\"what is the definition of botanics\")\n",
    "for parse in parses:\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'definition', 'np': 'mechanophilia'}\n"
     ]
    }
   ],
   "source": [
    "parses = grammar.parse_input(\"what does mechanophilia mean\")\n",
    "for parse in parses:\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter intents\n",
    "\n",
    "\"show me the third sense\"\n",
    "\n",
    "\"tell me more about the mathematical meaning\"\n",
    "\n",
    "\"show me some examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_to_num import alpha2digit\n",
    "\n",
    "def remove_suffix(word: str, suffix: str):\n",
    "    \"\"\"Remove a suffix from a string. \"\"\"\n",
    "    if word.endswith(suffix):\n",
    "        return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "def convert_ordinal(word: str):\n",
    "    \"\"\"Convert a number to ordinal\"\"\"\n",
    "    basic_forms = {\"first\": \"one\",\n",
    "                   \"second\": \"two\",\n",
    "                   \"third\": \"three\",\n",
    "                   \"fifth\": \"five\",\n",
    "                   \"twelfth\": \"twelve\"}\n",
    "    \n",
    "    for k, v in basic_forms.items():\n",
    "        word = word.replace(k, v)\n",
    "    \n",
    "    word = word.replace(\"ieth\", \"y\")\n",
    "    \n",
    "    for pattern in [\"st\", \"nd\", \"rd\", \"th\", \"°\"]:\n",
    "        word = remove_suffix(word, pattern)\n",
    "    \n",
    "    converted = alpha2digit(word, \"en\")\n",
    "    try:\n",
    "        return int(converted)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "class OrdinalNumberAnnotator(Annotator):\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) > 1:\n",
    "            return []\n",
    "        value = convert_ordinal(tokens[0])\n",
    "        if value:\n",
    "            return [('$OrdinalNumber', value)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$OrdinalNumber', 40)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrdinalNumberAnnotator().annotate(['fortieth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tools.dumps import wrap_open\n",
    "\n",
    "with wrap_open(\"wikidata/grammatical_categories.json\") as fp:\n",
    "    categories = pd.read_json(fp)\n",
    "    \n",
    "categories_set = set(categories[\"entityLabel.value\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"plural\" in categories_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity.value</th>\n",
       "      <th>entityLabel.value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>http://www.wikidata.org/entity/Q192613</td>\n",
       "      <td>present tense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1240211</td>\n",
       "      <td>present perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>http://www.wikidata.org/entity/Q3502553</td>\n",
       "      <td>present subjunctive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>http://www.wikidata.org/entity/Q7240943</td>\n",
       "      <td>present continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>http://www.wikidata.org/entity/Q9062494</td>\n",
       "      <td>present perfect in English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>http://www.wikidata.org/entity/Q10345583</td>\n",
       "      <td>present participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434162</td>\n",
       "      <td>present imperative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434245</td>\n",
       "      <td>present infinitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434511</td>\n",
       "      <td>present gerund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>http://www.wikidata.org/entity/Q56682909</td>\n",
       "      <td>present indicative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1763348</td>\n",
       "      <td>present participe in French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>http://www.wikidata.org/entity/Q10345583</td>\n",
       "      <td>present participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>http://www.wikidata.org/entity/Q52434245</td>\n",
       "      <td>present infinitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>http://www.wikidata.org/entity/Q12738495</td>\n",
       "      <td>present perfect continuous in English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>http://www.wikidata.org/entity/Q56649265</td>\n",
       "      <td>present imperfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>http://www.wikidata.org/entity/Q12738495</td>\n",
       "      <td>present perfect continuous in English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>http://www.wikidata.org/entity/Q12738495</td>\n",
       "      <td>present perfect continuous in English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 entity.value  \\\n",
       "136    http://www.wikidata.org/entity/Q192613   \n",
       "144   http://www.wikidata.org/entity/Q1240211   \n",
       "152   http://www.wikidata.org/entity/Q3502553   \n",
       "156   http://www.wikidata.org/entity/Q7240943   \n",
       "157   http://www.wikidata.org/entity/Q9062494   \n",
       "158  http://www.wikidata.org/entity/Q10345583   \n",
       "174  http://www.wikidata.org/entity/Q52434162   \n",
       "175  http://www.wikidata.org/entity/Q52434245   \n",
       "177  http://www.wikidata.org/entity/Q52434511   \n",
       "180  http://www.wikidata.org/entity/Q56682909   \n",
       "203   http://www.wikidata.org/entity/Q1763348   \n",
       "218  http://www.wikidata.org/entity/Q10345583   \n",
       "224  http://www.wikidata.org/entity/Q52434245   \n",
       "232  http://www.wikidata.org/entity/Q12738495   \n",
       "233  http://www.wikidata.org/entity/Q56649265   \n",
       "340  http://www.wikidata.org/entity/Q12738495   \n",
       "400  http://www.wikidata.org/entity/Q12738495   \n",
       "\n",
       "                         entityLabel.value  \n",
       "136                          present tense  \n",
       "144                        present perfect  \n",
       "152                    present subjunctive  \n",
       "156                     present continuous  \n",
       "157             present perfect in English  \n",
       "158                     present participle  \n",
       "174                     present imperative  \n",
       "175                     present infinitive  \n",
       "177                         present gerund  \n",
       "180                     present indicative  \n",
       "203            present participe in French  \n",
       "218                     present participle  \n",
       "224                     present infinitive  \n",
       "232  present perfect continuous in English  \n",
       "233                      present imperfect  \n",
       "340  present perfect continuous in English  \n",
       "400  present perfect continuous in English  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[categories['entityLabel.value'].str.startswith(\"present\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSAnnotator(Annotator):\n",
    "    def annotate(self, tokens):\n",
    "        candidate = \" \".join(tokens)\n",
    "        value = None\n",
    "        if candidate == \"noun\":\n",
    "            value = \"noun\"\n",
    "        if candidate == \"verb\":\n",
    "            value = \"verb\"\n",
    "        if candidate == \"adjective\":\n",
    "            value = \"adj\"\n",
    "        if candidate == \"adverb\":\n",
    "            value = \"adv\"\n",
    "        if candidate == \"pronoun\":\n",
    "            value = \"pron\"\n",
    "        if value:\n",
    "            return [('$POS', value)]\n",
    "        return []\n",
    "\n",
    "\n",
    "class GrammaticalFeatureAnnotator:\n",
    "    def annotate(self, tokens):\n",
    "        candidate = \" \".join(tokens)\n",
    "        if candidate in categories_set:\n",
    "            return [(\"$GrammaticalFeature\", candidate)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(type_):\n",
    "    def f(sems):\n",
    "        return merge_dicts({'filtertype': type_, 'value': sems[4]}, sems[1])\n",
    "    return f\n",
    "\n",
    "def as_constraint(sem):\n",
    "    return {'constraints': sem}\n",
    "    \n",
    "\n",
    "rules_filter = [\n",
    "    Rule('$ROOT', '$FilterQuery', lambda sems: merge_dicts({'intent': 'filter'}, sems[0])),\n",
    "    # Tell me about...\n",
    "    Rule('$FilterQuery', '?$ShowVerb $FilterQueryElements', sems_1),\n",
    "    # What about...\n",
    "    Rule('$FilterQuery', 'what about $FilterQueryElements', sems_2),\n",
    "    # What are the...\n",
    "    Rule('$FilterQuery', 'what $Be ?$Determiner $FilterQueryElements', lambda sems: sems[3]),\n",
    "    # \"which examples are available?\"\n",
    "    Rule('$FilterQuery', 'what $FilterQueryElements $be $More', sems_1),\n",
    "    Rule('$FilterQuery', 'which $FilterQueryElements $be $More', sems_1),\n",
    "    Rule('$FilterQuery', '$FilterQueryElements', sems_0),\n",
    "    \n",
    "    \n",
    "    # ordinal case\n",
    "    Rule('$FilterQueryElements', \"?$More the $OrdinalNumber ?$WordSense ?$Only\",\n",
    "         lambda sems: {'filtertype': 'number', 'value': strip_none(sems)[0]}),\n",
    "         \n",
    "    # \"more about the mathematical case\"\n",
    "    Rule('$FilterQueryElements', \"?$More the $UnquotedToken $WordSense ?$Only\",\n",
    "         lambda sems: {'filtertype': 'semantic', \"value\": strip_none(sems)[0]}),\n",
    "    \n",
    "    # some examples\n",
    "    Rule('$FilterQueryElements', '?$More $Extra', sems_1),\n",
    "    # some examples for the second case\n",
    "    Rule('$FilterQueryElements', '?$More $Extra $StopWord ?$Determiner $OrdinalNumber $WordSense ?$Only',\n",
    "         #lambda sems: merge_dicts({'type': 'number', 'value': sems[4]}, sems[1])),\n",
    "         foo('number')),\n",
    "         \n",
    "    # some examples for the botanical case\n",
    "    Rule('$FilterQueryElements', '?$More $Extra $StopWord ?$Determiner $UnquotedToken $WordSense ?$Only',\n",
    "         # lambda sems: merge_dicts({'type': 'sense_meaning', 'value': sems[4]}, sems[1])),\n",
    "         foo('semantic')),\n",
    "\n",
    "    # some examples as a verb\n",
    "    Rule('$FilterQueryElements', '?$More $Extra ?$Filler $StopWord ?$Determiner $POS',\n",
    "         # lambda sems: merge_dicts({'type': 'sense_meaning', 'value': sems[4]}, sems[1])),\n",
    "         lambda sems: merge_dicts({'filtertype': 'grammatical', 'requiredPos': sems[5]}, sems[1])),\n",
    "    \n",
    "    # Show me the plural form\n",
    "    Rule(\"$FilterQueryElements\", \"$Determiner $GrammaticalFeature ?form\",\n",
    "         lambda sems: {'filtertype': 'grammatical', 'grammaticalFeature': sems[1]}),\n",
    "    \n",
    "    # Ask for examples, categories or usages\n",
    "    Rule('$Extra', 'examples', {'variant': \"example\"}),\n",
    "    Rule('$Extra', 'categories', {'variant': \"categories\"}),\n",
    "    Rule('$Extra', 'usages', {'variant': \"usages\"}),\n",
    "    Rule('$Extra', 'senses', {'variant': \"senses\"}),\n",
    "    Rule('$Extra', 'parts of speech', {'variant': \"pos\"}),\n",
    "    Rule('$Extra', 'conjugate', {'variant': \"forms\"}),\n",
    "    Rule('$Extra', 'conjugation', {'variant': \"forms\"}),\n",
    "    Rule('$Extra', 'forms', {'variant': \"forms\"}),\n",
    "    \n",
    "    # Category question where category precedes the rest\n",
    "    Rule('$FilterQuery', \"$FilterCategoryQuery\",\n",
    "         lambda sems: merge_dicts({'filtertype': 'semantic'}, sems[0])),\n",
    "    # in the field of computer science, what does x mean?\n",
    "    Rule('$FilterCategoryQuery', \"$Category $WhatFilter\", sems_0),\n",
    "    Rule('$FilterCategoryQuery', \"$WhatFilter $Category\", sems_1),\n",
    "    Rule('$FilterCategoryQuery', \"$Category $?More $Extra\", merge_dicts_singleparam),\n",
    "    \n",
    "    \n",
    "    Rule('$More', \"more\"),\n",
    "    Rule('$More', \"more about\"),\n",
    "    Rule('$More', \"some\"),\n",
    "    Rule('$More', 'possible'),\n",
    "    Rule('$More', 'available'),\n",
    "    \n",
    "    Rule(\"$WordSense\", \"one\"),\n",
    "    Rule(\"$WordSense\", \"sense\"),\n",
    "    Rule(\"$WordSense\", \"meaning\"),\n",
    "    Rule(\"$WordSense\", \"definition\"),\n",
    "    Rule(\"$WordSense\", \"possibility\"),\n",
    "    Rule(\"$WordSense\", \"case\"),\n",
    "    Rule(\"$WordSense\", \"field\"),\n",
    "    \n",
    "    Rule(\"$Only\", \"only\"),\n",
    "    Rule(\"$Only\", \"alone\"),\n",
    "    \n",
    "    Rule(\"$Filler\", \"$StopWord $NounPhrase\"),\n",
    "    \n",
    "    Rule(\"$Category\", \"in $Determiner $WordSense $StopWord $NounPhrase ?,\", lambda sems: {'category': sems[4]['np']}),\n",
    "    Rule(\"$WhatFilter\", \"what does $NounPhrase mean\"),\n",
    "    Rule(\"$WhatFilter\", \"what $Be $Determiner $WordSense\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 70 rules.\n"
     ]
    }
   ],
   "source": [
    "annotators = [StopWordAnnotator(), ShowVerbAnnotator(),\n",
    "                TokenAnnotatorBuilder(\"$UnquotedToken\", [\"'\", '\"', \"?\", \",\"]), # commas must split noun phrases\n",
    "                OrdinalNumberAnnotator(), POSAnnotator(),\n",
    "                GrammaticalFeatureAnnotator()]\n",
    "\n",
    "rules_2 = rules_definition + rules_determiner + rules_filter + rules_be\n",
    "\n",
    "grammar_2 = Grammar(rules=rules_2, annotators=annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first'}\n",
      "{'intent': 'filter', 'filtertype': 'number', 'value': 1}\n",
      "{'intent': 'definition', 'np': 'the first one'}\n"
     ]
    }
   ],
   "source": [
    "parses = grammar_2.parse_input('tell me the first one')\n",
    "for parse in parses:\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'mathematical'}\n",
      "{'intent': 'definition', 'np': 'the mathematical one only'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('tell me the mathematical one only'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'variant': 'example'}\n",
      "{'intent': 'definition', 'np': 'more examples'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('tell me more examples'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('what about more examples for the first one'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'semantic', 'value': 'first', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'number', 'value': 1, 'variant': 'example'}\n",
      "{'intent': 'definition', 'np': 'more examples for the first one'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('show me more examples for the first one'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'noun', 'variant': 'example'}\n",
      "{'intent': 'definition', 'np': 'more examples as a noun'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('show me more examples as a noun'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'definition', 'np': 'more examples of home as a verb'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('show me more examples of home as a verb'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('more examples of home as a verb'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'semantic', 'category': 'biology'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('in the field of biology, what is the definition'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'semantic', 'category': 'computer science'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('what does it mean in the field of computer science'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'filtertype': 'grammatical', 'grammaticalFeature': 'singular'}\n",
      "{'intent': 'definition', 'np': 'the singular form'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('tell me the singular form'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'variant': 'pos'}\n",
      "{'intent': 'definition', 'np': 'the available parts of speech'}\n",
      "{'intent': 'definition', 'np': 'available parts of speech'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('what are the available parts of speech'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: Question Answering demo\n",
    "\n",
    "By now we'll ignore that a parsed sentence may (and usually does) bring about multiple semantics.\n",
    "\n",
    "Instead, we'll hardcode a \"simple\" priority choice: take the semantics with the greatest number of keys. It should work in a number of situations.\n",
    "\n",
    "In case the choices are only definitions, pick the one with the shortest np.\n",
    "\n",
    "In case I have to choose between two filters, always prefer the number type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.providers import WiktionaryProvider\n",
    "from tools.answering import QuestionAnsweringContext, DefinitionIntent, FilterIntent\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "provider = WiktionaryProvider()\n",
    "\n",
    "def pick_best_semantics(parses):\n",
    "    \"\"\"\n",
    "    Return the most likely matching parse.\n",
    "    \n",
    "    This is a simple stub. Does not do any ML here, despite it could\n",
    "    (and should), so use with care.\n",
    "    \"\"\"\n",
    "    if parses == []:\n",
    "        return {}\n",
    "    semantics = [parse.semantics for parse in parses]\n",
    "    \n",
    "    if all(parse[\"intent\"] == \"definition\" for parse in semantics):\n",
    "        picked_parser = min(semantics, key=lambda parse: len(parse[\"np\"]))\n",
    "    \n",
    "    else:\n",
    "        priority = {'grammatical': 1, 'semantic': 3, 'number': 2}\n",
    "        picked_parser = max(semantics, key=lambda parse: len(parse.keys()) * 10 + (priority[parse['type']] if 'type' in parse else 0))\n",
    "        \n",
    "    return picked_parser\n",
    "\n",
    "context = QuestionAnsweringContext()\n",
    "\n",
    "def answer_question(grammar: Grammar, question: str):\n",
    "    question = question.lower()\n",
    "    \n",
    "    for eos in [\".\", \"?\", \"!\"]:\n",
    "        question = remove_suffix(question, eos)\n",
    "    \n",
    "    parses = grammar.parse_input(question)\n",
    "    best_semantics = pick_best_semantics(parses)\n",
    "    \n",
    "    print(best_semantics)\n",
    "    \n",
    "    if best_semantics['intent'] == 'definition':\n",
    "        display(HTML(context.handle_intent(DefinitionIntent(best_semantics['np'])).message))\n",
    "    elif best_semantics['intent'] == 'filter':\n",
    "        if best_semantics['type'] == 'number':\n",
    "            display(HTML(context.handle_intent(FilterIntent('single', best_semantics['value'])).message))\n",
    "        # ???"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pick_best_semantics(grammar_2.parse_input('what about more examples for the first one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter', 'variant': 'example'}"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('show me some examples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter',\n",
       " 'filtertype': 'semantic',\n",
       " 'value': 'botanics',\n",
       " 'variant': 'example'}"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('more examples for the botanics one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter',\n",
       " 'filtertype': 'semantic',\n",
       " 'value': 'first',\n",
       " 'variant': 'example'}"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('show me more examples for the first one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'butterfly'}"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best_semantics(grammar_2.parse_input('define butterfly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with wrap_open(\"intents/sample.json\") as fp:\n",
    "    dataset = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sessions': [{'title': 'Define only',\n",
       "   'turns': [{'utterance': \"define 'pi'\",\n",
       "     'target': {'intent': 'definition', 'np': 'pi'}},\n",
       "    {'utterance': \"what is an 'apple'\",\n",
       "     'target': {'intent': 'definition', 'np': 'apple'}},\n",
       "    {'utterance': 'what is the definition of botanics',\n",
       "     'target': {'intent': 'definition', 'np': 'botanics'}},\n",
       "    {'utterance': 'what does mechanophilia mean',\n",
       "     'target': {'intent': 'definition', 'np': 'mechanophilia'}},\n",
       "    {'utterance': \"show me all meanings for 'desire'\",\n",
       "     'target': {'intent': 'definition', 'np': 'desire', 'quantifier': 'all'}},\n",
       "    {'utterance': 'what is apollo',\n",
       "     'target': {'intent': 'definition', 'np': 'apollo'}},\n",
       "    {'utterance': 'who is apollo',\n",
       "     'target': {'intent': 'definition', 'np': 'apollo', 'is_person': True}},\n",
       "    {'utterance': 'show me all examples for stashes',\n",
       "     'target': {'intent': 'definition',\n",
       "      'np': 'stashes',\n",
       "      'all': True,\n",
       "      'variant': 'example'}}]},\n",
       "  {'title': 'Filter intent only',\n",
       "   'turns': [{'utterance': 'tell me the first one',\n",
       "     'target': {'intent': 'filter', 'filtertype': 'number', 'value': 1}},\n",
       "    {'utterance': 'tell me the mathematical one only',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'semantic',\n",
       "      'value': 'mathematical'}},\n",
       "    {'utterance': 'what about more examples for the first one',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'semantic',\n",
       "      'value': 'first',\n",
       "      'variant': 'example'}},\n",
       "    {'utterance': 'show me more examples for the first one',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'semantic',\n",
       "      'value': 'first',\n",
       "      'variant': 'example'}},\n",
       "    {'utterance': 'show me examples as a noun',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'grammatical',\n",
       "      'required_pos': 'noun',\n",
       "      'variant': 'example'}},\n",
       "    {'utterance': 'show me more examples of home as a verb',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'grammatical',\n",
       "      'required_pos': 'verb',\n",
       "      'variant': 'example'}},\n",
       "    {'utterance': 'what does it mean in the field of computer science',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'semantic',\n",
       "      'category': 'computer science'}},\n",
       "    {'utterance': 'in the field of biology, what is the definition',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'semantic',\n",
       "      'category': 'biology'}},\n",
       "    {'utterance': 'tell me the singular form',\n",
       "     'target': {'intent': 'filter',\n",
       "      'filtertype': 'grammatical',\n",
       "      'requiredForm': 'singular'}},\n",
       "    {'utterance': 'what are the available categories',\n",
       "     'target': {'intent': 'filter', 'variant': 'categories'}},\n",
       "    {'utterance': 'possible usages',\n",
       "     'target': {'intent': 'filter', 'variant': 'usages'}}]}]}"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import copy\n",
    "\n",
    "class SamplePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X=None, Y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, dataset):\n",
    "        # simply return sessions as an array\n",
    "        df = copy.deepcopy(dataset)\n",
    "        sessions = df['sessions']\n",
    "        for session in sessions:\n",
    "            for turn in session['turns']:\n",
    "                del turn['target']\n",
    "            session['turns'] = [turn['utterance'] for turn in session['turns']]\n",
    "        return sessions\n",
    "\n",
    "sessions = SamplePreprocessor().fit_transform(dataset)\n",
    "targets = [[turn['target'] for turn in session['turns']] for session in dataset['sessions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'intent': 'definition', 'np': 'pi'},\n",
       "  {'intent': 'definition', 'np': 'apple'},\n",
       "  {'intent': 'definition', 'np': 'botanics'},\n",
       "  {'intent': 'definition', 'np': 'mechanophilia'},\n",
       "  {'intent': 'definition', 'np': 'desire', 'quantifier': 'all'},\n",
       "  {'intent': 'definition', 'np': 'apollo'},\n",
       "  {'intent': 'definition', 'np': 'apollo', 'is_person': True},\n",
       "  {'intent': 'definition',\n",
       "   'np': 'stashes',\n",
       "   'all': True,\n",
       "   'variant': 'example'}],\n",
       " [{'intent': 'filter', 'filtertype': 'number', 'value': 1},\n",
       "  {'intent': 'filter', 'filtertype': 'semantic', 'value': 'mathematical'},\n",
       "  {'intent': 'filter',\n",
       "   'filtertype': 'semantic',\n",
       "   'value': 'first',\n",
       "   'variant': 'example'},\n",
       "  {'intent': 'filter',\n",
       "   'filtertype': 'semantic',\n",
       "   'value': 'first',\n",
       "   'variant': 'example'},\n",
       "  {'intent': 'filter',\n",
       "   'filtertype': 'grammatical',\n",
       "   'required_pos': 'noun',\n",
       "   'variant': 'example'},\n",
       "  {'intent': 'filter',\n",
       "   'filtertype': 'grammatical',\n",
       "   'required_pos': 'verb',\n",
       "   'variant': 'example'},\n",
       "  {'intent': 'filter',\n",
       "   'filtertype': 'semantic',\n",
       "   'category': 'computer science'},\n",
       "  {'intent': 'filter', 'filtertype': 'semantic', 'category': 'biology'},\n",
       "  {'intent': 'filter',\n",
       "   'filtertype': 'grammatical',\n",
       "   'requiredForm': 'singular'},\n",
       "  {'intent': 'filter', 'variant': 'categories'},\n",
       "  {'intent': 'filter', 'variant': 'usages'}]]"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Define only',\n",
       "  'turns': [\"define 'pi'\",\n",
       "   \"what is an 'apple'\",\n",
       "   'what is the definition of botanics',\n",
       "   'what does mechanophilia mean',\n",
       "   \"show me all meanings for 'desire'\",\n",
       "   'what is apollo',\n",
       "   'who is apollo',\n",
       "   'show me all examples for stashes']},\n",
       " {'title': 'Filter intent only',\n",
       "  'turns': ['tell me the first one',\n",
       "   'tell me the mathematical one only',\n",
       "   'what about more examples for the first one',\n",
       "   'show me more examples for the first one',\n",
       "   'show me examples as a noun',\n",
       "   'show me more examples of home as a verb',\n",
       "   'what does it mean in the field of computer science',\n",
       "   'in the field of biology, what is the definition',\n",
       "   'tell me the singular form',\n",
       "   'what are the available categories',\n",
       "   'possible usages']}]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarMatcher(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"This class serves as an evaluation framework for an intent classifier\"\"\"\n",
    "    def __init__(self, grammar: Grammar):\n",
    "        self.grammar = grammar\n",
    "\n",
    "    def fit(self, sessions=None, targets=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, sessions):\n",
    "        \"\"\"\n",
    "        Convert the given sessions to intents.\n",
    "        Sessions is expected to be the output of SampleProcessor.\n",
    "        \"\"\"\n",
    "        targets = []\n",
    "        for session in sessions:\n",
    "            answers = []\n",
    "            for utterance in session['turns']:\n",
    "                answers.append(self.grammar.parse_input(utterance))\n",
    "            targets.append(answers)\n",
    "        return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyMatcher(BaseEstimator, ClassifierMixin):  \n",
    "    def fit(self, sessions=None, target=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, sessions):\n",
    "        target = []\n",
    "        for session in sessions:\n",
    "            turns = []\n",
    "            for parses in session:\n",
    "                try:\n",
    "                    turns.append(pick_best_semantics(parses))\n",
    "                except (e):\n",
    "                    turns.append({})\n",
    "            target.append(turns)\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_matcher = Pipeline([('preprocessor', SamplePreprocessor()),\n",
    "                                ('grammar_matcher', GrammarMatcher(grammar_2)),\n",
    "                                ('picker', GreedyMatcher())])\n",
    "\n",
    "greedy_matcher.fit(dataset, targets)\n",
    "output = greedy_matcher.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'definition', 'np': 'desire', 'quantifier': 'all'} {}\n",
      "{'intent': 'definition', 'np': 'stashes', 'all': True, 'variant': 'example'} {'intent': 'definition', 'np': 'all examples for stashes'}\n",
      "{'intent': 'filter', 'filtertype': 'number', 'value': 1} {'intent': 'filter', 'filtertype': 'semantic', 'value': 'first'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'required_pos': 'noun', 'variant': 'example'} {'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'noun', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'required_pos': 'verb', 'variant': 'example'} {'intent': 'filter', 'filtertype': 'grammatical', 'requiredPos': 'verb', 'variant': 'example'}\n",
      "{'intent': 'filter', 'filtertype': 'grammatical', 'requiredForm': 'singular'} {'intent': 'filter', 'filtertype': 'grammatical', 'grammaticalFeature': 'singular'}\n",
      "{'intent': 'filter', 'variant': 'categories'} {'intent': 'definition', 'np': 'available categories'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7763157894736841"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A bunch of evaluation functions\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# \"perfect\" scorers, because they check whether two values are equal\n",
    "def perfect_accuracy(y_truth, y_pred, debug=False):\n",
    "    # Concatenate lists-of-lists into flattened lists.\n",
    "    # Not the most efficient, but I find it very neat\n",
    "    y_truth = sum(y_truth, [])\n",
    "    y_pred = sum(y_pred, [])\n",
    "    \n",
    "    score = []\n",
    "    for y_t, y_p in zip(y_truth, y_pred):\n",
    "        matched_items = len(set(y_t.items()) & set(y_p.items()))\n",
    "        score.append(matched_items / len(y_t))\n",
    "        if debug and score[-1] < 1.0:\n",
    "            print(y_t, y_p)\n",
    "        \n",
    "    return np.average(score)\n",
    "\n",
    "def intent_match_score(y_truth, y_pred):\n",
    "    y_pred = [intent['intent'] if len(intent) else '' for intent in sum(y_pred, [])]\n",
    "    y_truth = [intent['intent'] if len(intent) else '' for intent in sum(y_truth, [])]\n",
    "    \n",
    "    return precision_recall_fscore_support(y_truth, y_pred)\n",
    "\n",
    "perfect_accuracy(targets, outputs, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'definition', 'np': 'butterfly'}\n",
      "Current state of the entities:  <tools.answering.DefinitionEntity object at 0x7efc2b793a90>\n",
      "Serializing an answer here...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Found the following meanings<ul></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(grammar_2, \"define butterfly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'type': 'number', 'value': 2}\n",
      "Current state of the entities:  <tools.answering.DefinitionEntity object at 0x7efc2b793a90>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (1,1, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-55b77863b421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"more about the second one\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-a7d6fadd9b6e>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(grammar, question)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbest_semantics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'filter'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbest_semantics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'number'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_intent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFilterIntent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'single'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_semantics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# ???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/knowledge-glue/notebooks/tools/answering.py\u001b[0m in \u001b[0;36mhandle_intent\u001b[0;34m(self, intent)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mmax_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msenses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfailed_intent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"This sense does not exist! Try asking me to fetch the {randint(1, max_range)})°\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                     \u001b[0msense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msenses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"More details on the item no. {number}: <br>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (1,1, 0)"
     ]
    }
   ],
   "source": [
    "answer_question(grammar_2, \"more about the second one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
