{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sippycup semantic parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('3rdparty/sippycup')\n",
    "from annotator import *\n",
    "from parsing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rule(grammar, rule):\n",
    "    if contains_optionals(rule):\n",
    "        add_rule_containing_optional(grammar, rule)\n",
    "    elif is_lexical(rule):\n",
    "        grammar.lexical_rules[rule.rhs].append(rule)\n",
    "    elif is_unary(rule):\n",
    "        grammar.unary_rules[rule.rhs].append(rule)\n",
    "    elif is_binary(rule):\n",
    "        grammar.binary_rules[rule.rhs].append(rule)\n",
    "    elif all([is_cat(rhsi) for rhsi in rule.rhs]):\n",
    "        add_n_ary_rule(grammar, rule)\n",
    "    else:\n",
    "        make_cat(grammar, rule)\n",
    "        # raise Exception('RHS mixes terminals and non-terminals: %s' % rule\n",
    "\n",
    "def add_rule_containing_optional(grammar, rule):\n",
    "    # Find index of the first optional element on the RHS.\n",
    "    first = next((idx for idx, elt in enumerate(rule.rhs) if is_optional(elt)), -1)\n",
    "    assert first >= 0\n",
    "    assert len(rule.rhs) > 1, 'Entire RHS is optional: %s' % rule\n",
    "    prefix = rule.rhs[:first]\n",
    "    suffix = rule.rhs[(first + 1):]\n",
    "    # First variant: the first optional element gets deoptionalized.\n",
    "    deoptionalized = (rule.rhs[first][1:],)\n",
    "    add_rule(grammar, Rule(rule.lhs, prefix + deoptionalized + suffix, rule.sem))\n",
    "    # Second variant: the first optional element gets removed.\n",
    "    # If the semantics is a value, just keep it as is.\n",
    "    sem = rule.sem\n",
    "    # But if it's a function, we need to supply a dummy argument for the removed element.\n",
    "    if isinstance(rule.sem, FunctionType):\n",
    "        sem = lambda sems: rule.sem(sems[:first] + [None] + sems[first:])\n",
    "    add_rule(grammar, Rule(rule.lhs, prefix + suffix, sem))\n",
    "\n",
    "def make_cat(grammar, rule):\n",
    "    \"\"\"\n",
    "    Convert a terminal in the RHS into a non-terminal.\n",
    "    \n",
    "    Conversion works by creating a nonterminal from each terminal if\n",
    "    it does not exist already in the grammar, otherwise it just replaces it.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_rhs = []\n",
    "    for rhsi in rule.rhs:\n",
    "        if is_cat(rhsi):\n",
    "            cat_name = rhsi\n",
    "        else:\n",
    "            cat_name = \"$\" + rhsi + \"__nonterminal\"\n",
    "            if cat_name not in grammar.categories:\n",
    "                grammar.categories.add(cat_name)\n",
    "                # print(f\"Adding rule: {cat_name} := {str(rhsi)}\")\n",
    "                add_rule(grammar, Rule(cat_name, rhsi))\n",
    "        new_rhs.append(cat_name)\n",
    "        # print(f\"Adding rule: {rule.lhs} := {str(new_rhs)}\")\n",
    "    add_rule(grammar, Rule(rule.lhs, tuple(new_rhs), rule.sem))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(grammar, input):\n",
    "    \"\"\"Returns a list of all parses for input using grammar.\"\"\"\n",
    "    tokens_spacy = nlp(input) # New\n",
    "    tokens = [token.text for token in tokens_spacy]\n",
    "    chart = defaultdict(list)\n",
    "    for j in range(1, len(tokens) + 1):\n",
    "        for i in range(j - 1, -1, -1):\n",
    "            apply_annotators(grammar, chart, tokens, i, j)\n",
    "            apply_lexical_rules(grammar, chart, tokens, i, j)\n",
    "            apply_binary_rules(grammar, chart, i, j)\n",
    "            apply_unary_rules(grammar, chart, i, j)\n",
    "    parses = chart[(0, len(tokens))]\n",
    "    if hasattr(grammar, 'start_symbol') and grammar.start_symbol:\n",
    "        parses = [parse for parse in parses if parse.rule.lhs == grammar.start_symbol]\n",
    "    return parses\n",
    "\n",
    "class Grammar:\n",
    "    def __init__(self, rules=[], annotators=[], start_symbol='$ROOT'):\n",
    "        self.categories = set()\n",
    "        self.lexical_rules = defaultdict(list)\n",
    "        self.unary_rules = defaultdict(list)\n",
    "        self.binary_rules = defaultdict(list)\n",
    "        self.annotators = annotators\n",
    "        self.start_symbol = start_symbol\n",
    "        for rule in rules:\n",
    "            add_rule(self, rule)\n",
    "        print('Created grammar with %d rules.' % len(rules))\n",
    "\n",
    "    def parse_input(self, input):\n",
    "        \"\"\"Returns a list of parses for the given input.\"\"\"\n",
    "        return parse_input(self, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$Number', 16)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumberAnnotator().annotate(['16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$Token', 'foo')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenAnnotator().annotate(['foo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopWordAnnotator(Annotator):\n",
    "    \"\"\"Let spacy detect stop words for us\"\"\"\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) == 1:\n",
    "            if nlp(tokens[0])[0].is_stop:\n",
    "                return [('$StopWord', tokens[0])]\n",
    "        return []\n",
    "\n",
    "class ShowVerbAnnotator(Annotator):\n",
    "    def __init__(self, threshold = 0.7):\n",
    "        self.show_verbs = [(\"define\", \"\"), (\"tell\", \"me\"), (\"show\", \"me\")]\n",
    "        self.spacy_show_toks = nlp(\" \".join([verb for verb, _ in self.show_verbs]))\n",
    "        self.threshold = 0.7\n",
    "\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) <= 2:\n",
    "            spacy_tokens = nlp(\" \".join(tokens))\n",
    "            spacy_token = spacy_tokens[0]\n",
    "            if spacy_token.pos_ != 'VERB':\n",
    "                return []\n",
    "            \n",
    "            # If the verb matches in meaning and, in case it requires a\n",
    "            # follow-up word, that this matches as well, then it's a match.\n",
    "            for idx, (verb, acc) in enumerate(self.show_verbs):\n",
    "                spacy_verb = self.spacy_show_toks[idx]\n",
    "                if spacy_token.similarity(spacy_verb) >= self.threshold:\n",
    "                    if verb == tokens[0] and acc != \"\" and (len(tokens) == 1 or tokens[1] != acc):\n",
    "                        return []\n",
    "                    return [('$ShowVerb', tokens)]\n",
    "        return []\n",
    "\n",
    "    \n",
    "class TokenAnnotatorBuilder(Annotator):\n",
    "    def __init__(self, category_name, excluded):\n",
    "        Annotator.__init__(self)\n",
    "        self.category_name = category_name\n",
    "        self.excluded = excluded\n",
    "    \n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) == 1:\n",
    "            token = tokens[0]\n",
    "            if token not in self.excluded:\n",
    "                return [(self.category_name, token)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['say'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['say'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['define'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['define'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ShowVerb', ['tell', 'me'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowVerbAnnotator().annotate(['tell', 'me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TokenWithoutQuotes', 'Jeff')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenAnnotatorBuilder('TokenWithoutQuotes', ['\"', '\"']).annotate(['Jeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CELL_CAPACITY = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar definition\n",
    "\n",
    "We will model the queries after a few intents:\n",
    "\n",
    "- Definition: asking for a definition of a noun phrase\n",
    "- Comparison: compare two noun phrases\n",
    "- Filtering/Details on a given sense: ask for further details on a previously mentioned sense\n",
    "- Usage of form\n",
    "- General grammar knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def sems_0(sems):\n",
    "    return sems[0]\n",
    "\n",
    "def sems_1(sems):\n",
    "    return sems[1]\n",
    "\n",
    "def merge_dicts(d1, d2):\n",
    "    if not d2:\n",
    "        return d1\n",
    "    if not d1:\n",
    "        return {}\n",
    "    return {**d1, **d2}\n",
    "\n",
    "def strip_none(sems):\n",
    "    return [sem for sem in sems if sem]\n",
    "\n",
    "def merge_dicts_singleparam(sems):\n",
    "    if all([sem is None for sem in sems]):\n",
    "        return {}\n",
    "    return reduce(merge_dicts, strip_none(sems))\n",
    "\n",
    "def to_np(sems):\n",
    "    return {'np': strip_none(sems)[0]}\n",
    "\n",
    "def concatenate(sems):\n",
    "    return \" \".join(strip_none(sems))\n",
    "\n",
    "\n",
    "rules_definition = [\n",
    "    Rule('$ROOT', '$DefinitionQuery', sems_0),\n",
    "    Rule('$DefinitionQuery', '$DefinitionQueryElements',\n",
    "         lambda sems: merge_dicts({'intent': 'definition'}, sems[0])),\n",
    "    Rule('$DefinitionQueryElements', '$DefinitionQuestion $NounPhrase',\n",
    "         merge_dicts_singleparam),\n",
    "    \n",
    "    Rule('$DefinitionQuestion', '$ShowVerb ?me'),\n",
    "    Rule('$DefinitionQuestion', '$WhatDefinition'),\n",
    "    Rule('$WhatDefinition', 'what is ?$Determiner ?$DefinitionFor'),\n",
    "    Rule('$WhatDefinition', 'how do you $ShowVerb'),\n",
    "    Rule('$DefinitionFor', 'meaning $StopWord'),\n",
    "    Rule('$DefinitionFor', 'sense $StopWord'),\n",
    "    Rule('$DefinitionFor', 'definition $StopWord'),\n",
    "    Rule('$NounPhrase', \"$Tokens\", to_np),\n",
    "    Rule('$NounPhrase', \"' $Tokens '\", to_np),\n",
    "    Rule('$NounPhrase', '\" $Tokens \"', to_np),\n",
    "    Rule('$Tokens', '$UnquotedToken ?$Tokens', concatenate)\n",
    "]\n",
    "\n",
    "rules_determiner = [\n",
    "    Rule('$Determiner', 'a'),\n",
    "    Rule('$Determiner', 'an'),\n",
    "    Rule('$Determiner', 'the'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 20 rules.\n"
     ]
    }
   ],
   "source": [
    "annotators = [StopWordAnnotator(), ShowVerbAnnotator(), TokenAnnotatorBuilder(\"$UnquotedToken\", [\"'\", '\"', \"?\"])]\n",
    "rules = rules_definition + rules_end_of_sentence + rules_determiner\n",
    "grammar = Grammar(rules=rules, annotators=annotators)\n",
    "parses = grammar.parse_input('define pi')\n",
    "parse = parses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'pi'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse.semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input('define \"pi\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'pi'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $ROOT ('$DefinitionQuery',)\n",
      "|\n",
      "-- $DefinitionQuery ('$DefinitionQueryElements',)\n",
      "|\n",
      "---- $DefinitionQueryElements ('$DefinitionQuestion', '$NounPhrase')\n",
      "|\n",
      "------ $DefinitionQuestion ('$ShowVerb',)\n",
      "|\n",
      "-------- $ShowVerb ('define',)\n",
      "|\n",
      "------ $NounPhrase ('$\"__nonterminal', '$NounPhrase_$\"__nonterminal')\n",
      "|\n",
      "-------- $\"__nonterminal ('\"',)\n",
      "|\n",
      "-------- $NounPhrase_$\"__nonterminal ('$Tokens', '$\"__nonterminal')\n",
      "|\n",
      "---------- $Tokens ('$UnquotedToken',)\n",
      "|\n",
      "------------ $UnquotedToken ('pi',)\n",
      "|\n",
      "---------- $\"__nonterminal ('\"',)\n"
     ]
    }
   ],
   "source": [
    "def pretty_print(parse, depth=0):\n",
    "    if not isinstance(parse, str):\n",
    "        if depth > 0:\n",
    "            for _ in range(1):\n",
    "                print(\"|\")\n",
    "        print(\"-\" * depth * 2, parse.rule.lhs, parse.rule.rhs)\n",
    "        for child in parse.children:\n",
    "            pretty_print(child, depth+1)\n",
    "\n",
    "pretty_print(parses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input(\"define 'pi'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input(\"tell me the life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'the life'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input(\"what is an 'apple'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'apple'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "parses = grammar.parse_input(\"what is the definition of botanics?\")\n",
    "for parse in parses:\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter intents\n",
    "\n",
    "\"show me the third sense\"\n",
    "\n",
    "\"tell me more about the mathematical meaning\"\n",
    "\n",
    "\"show me some examples\"\n",
    "\n",
    "\"show me related words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_to_num import alpha2digit\n",
    "\n",
    "def remove_suffix(word: str, suffix: str):\n",
    "    \"\"\"Remove a suffix from a string. \"\"\"\n",
    "    if word.endswith(suffix):\n",
    "        return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "def convert_ordinal(word: str):\n",
    "    \"\"\"Convert a number to ordinal\"\"\"\n",
    "    basic_forms = {\"first\": \"one\",\n",
    "                   \"second\": \"two\",\n",
    "                   \"third\": \"three\",\n",
    "                   \"fifth\": \"five\",\n",
    "                   \"twelfth\": \"twelve\"}\n",
    "    \n",
    "    for k, v in basic_forms.items():\n",
    "        word = word.replace(k, v)\n",
    "    \n",
    "    word = word.replace(\"ieth\", \"y\")\n",
    "    \n",
    "    for pattern in [\"st\", \"nd\", \"rd\", \"th\", \"Â°\"]:\n",
    "        word = remove_suffix(word, pattern)\n",
    "    \n",
    "    converted = alpha2digit(word, \"en\")\n",
    "    try:\n",
    "        return int(converted)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "class OrdinalNumberAnnotator(Annotator):\n",
    "    def annotate(self, tokens):\n",
    "        if len(tokens) > 1:\n",
    "            return []\n",
    "        value = convert_ordinal(tokens[0])\n",
    "        if value:\n",
    "            return [('$OrdinalNumber', value)]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$OrdinalNumber', 40)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrdinalNumberAnnotator().annotate(['fortieth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(type_):\n",
    "    def f(sems):\n",
    "        return merge_dicts({'type': type_, 'value': sems[4]}, sems[1])\n",
    "    return f\n",
    "\n",
    "rules_filter = [\n",
    "    Rule('$ROOT', '$FilterQuery', sems_0),\n",
    "    Rule('$FilterQuery', '?$ShowVerb $FilterQueryElements',\n",
    "         lambda sems: merge_dicts({'intent': 'filter'}, sems[1])),\n",
    "    \n",
    "    Rule('$FilterQuery', 'what about $FilterQueryElements',\n",
    "         lambda sems: merge_dicts({'intent': 'filter'}, sems[2])),\n",
    "    \n",
    "    # ordinal case\n",
    "    Rule('$FilterQueryElements', \"?$More the $OrdinalNumber ?$WordSense ?$Only\",\n",
    "         lambda sems: {'type': 'number', 'value': strip_none(sems)[0]}),\n",
    "    \n",
    "    # \"more about the mathematical case\"\n",
    "    Rule('$FilterQueryElements', \"?$More the $UnquotedToken $WordSense ?$Only\",\n",
    "         lambda sems: {'type': 'sense_meaning', \"value\": strip_none(sems)[0]}),\n",
    "    \n",
    "    # some examples\n",
    "    Rule('$FilterQueryElements', '?$More $Extra', sems_1),\n",
    "    # some examples for the second case\n",
    "    Rule('$FilterQueryElements', '?$More $Extra $StopWord ?$Determiner $OrdinalNumber $WordSense ?$Only',\n",
    "         #lambda sems: merge_dicts({'type': 'number', 'value': sems[4]}, sems[1])),\n",
    "         foo('number')),\n",
    "    \n",
    "    # some examples for the botanical case\n",
    "    Rule('$FilterQueryElements', '?$More $Extra $StopWord ?$Determiner $UnquotedToken $WordSense ?$Only',\n",
    "         # lambda sems: merge_dicts({'type': 'sense_meaning', 'value': sems[4]}, sems[1])),\n",
    "         foo('sense_meaning')),\n",
    "    \n",
    "    \n",
    "    Rule('$Extra', 'examples', {'variant': \"example\"}),\n",
    "    Rule('$Extra', 'related words', {'variant': 'related'}),\n",
    "    \n",
    "    Rule('$More', \"more\"),\n",
    "    Rule('$More', \"more about\"), # TODO: add optionals for terminals as well\n",
    "    Rule('$More', \"some\"),\n",
    "    \n",
    "    Rule(\"$WordSense\", \"one\"),\n",
    "    Rule(\"$WordSense\", \"sense\"),\n",
    "    Rule(\"$WordSense\", \"meaning\"),\n",
    "    Rule(\"$WordSense\", \"definition\"),\n",
    "    Rule(\"$WordSense\", \"possibility\"),\n",
    "    Rule(\"$WordSense\", \"case\"),\n",
    "    \n",
    "    Rule(\"$Only\", \"only\"),\n",
    "    Rule(\"$Only\", \"alone\"),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 41 rules.\n"
     ]
    }
   ],
   "source": [
    "annotators = [StopWordAnnotator(), ShowVerbAnnotator(),\n",
    "                TokenAnnotatorBuilder(\"$UnquotedToken\", [\"'\", '\"', \"?\"]),\n",
    "                OrdinalNumberAnnotator()]\n",
    "\n",
    "rules_2 = rules_definition + rules_end_of_sentence + rules_determiner + rules_filter\n",
    "\n",
    "grammar_2 = Grammar(rules=rules_2, annotators=annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'type': 'sense_meaning', 'value': 'first'}\n",
      "{'intent': 'filter', 'type': 'number', 'value': 1}\n",
      "{'intent': 'definition', 'np': 'the first one'}\n"
     ]
    }
   ],
   "source": [
    "parses = grammar_2.parse_input('tell me the first one')\n",
    "for parse in parses:\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'type': 'sense_meaning', 'value': 'mathematical'}\n",
      "{'intent': 'definition', 'np': 'the mathematical one only'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('tell me the mathematical one only'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'variant': 'example'}\n",
      "{'intent': 'definition', 'np': 'more examples'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('tell me more examples'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'type': 'sense_meaning', 'value': 'first', 'variant': 'example'}\n",
      "{'intent': 'filter', 'type': 'number', 'value': 1, 'variant': 'example'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('what about more examples for the first one'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'type': 'sense_meaning', 'value': 'first', 'variant': 'example'}\n",
      "{'intent': 'filter', 'type': 'number', 'value': 1, 'variant': 'example'}\n",
      "{'intent': 'definition', 'np': 'more examples for the first one'}\n"
     ]
    }
   ],
   "source": [
    "for parse in grammar_2.parse_input('show me more examples for the first one'):\n",
    "    print(parse.semantics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: Question Answering demo\n",
    "\n",
    "By now we'll ignore that a parsed sentence may (and usually does) bring about multiple semantics.\n",
    "\n",
    "Instead, we'll hardcode a \"simple\" priority choice: take the semantics with the greatest number of keys. It should work in a number of situations.\n",
    "\n",
    "In case the choices are only definitions, pick the one with the shortest np.\n",
    "\n",
    "In case I have to choose between two filters, always prefer the number type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.providers import WiktionaryProvider\n",
    "from tools.answering import QuestionAnsweringContext, DefinitionIntent, FilterIntent\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "provider = WiktionaryProvider()\n",
    "\n",
    "def pick_best_semantics(parses):\n",
    "    semantics = [parse.semantics for parse in parses]\n",
    "    \n",
    "    if all(parse[\"intent\"] == \"definition\" for parse in semantics):\n",
    "        picked_parser = min(semantics, key=lambda parse: len(parse[\"np\"]))\n",
    "    \n",
    "    else:\n",
    "        priority = {'sense_meaning': 1, 'number': 2}\n",
    "        picked_parser = max(semantics, key=lambda parse: len(parse.keys()) * 10 + priority[parse['type']])\n",
    "        \n",
    "    return picked_parser\n",
    "\n",
    "context = QuestionAnsweringContext()\n",
    "\n",
    "def answer_question(grammar: Grammar, question: str):\n",
    "    question = question.lower()\n",
    "    \n",
    "    for eos in [\".\", \"?\", \"!\"]:\n",
    "        question = remove_suffix(question, eos)\n",
    "    \n",
    "    parses = grammar.parse_input(question)\n",
    "    best_semantics = pick_best(parses)\n",
    "    \n",
    "    print(best_semantics)\n",
    "    \n",
    "    if best_semantics['intent'] == 'definition':\n",
    "        display(HTML(context.handle_intent(DefinitionIntent(best_semantics['np'])).message))\n",
    "    elif best_semantics['intent'] == 'filter':\n",
    "        if best_semantics['type'] == 'number':\n",
    "            display(HTML(context.handle_intent(FilterIntent('single', best_semantics['value'])).message))\n",
    "        # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter', 'type': 'number', 'value': 1, 'variant': 'example'}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best(grammar_2.parse_input('what about more examples for the first one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'filter',\n",
       " 'type': 'sense_meaning',\n",
       " 'value': 'botanics',\n",
       " 'variant': 'example'}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best(grammar_2.parse_input('more examples for the botanics one'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'definition', 'np': 'butterfly'}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_best(grammar_2.parse_input('define butterfly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'definition', 'np': 'butterfly'}\n",
      "Current state of the entities:  None\n",
      "Dataset wiktionary/butterfly.json already downloaded. Skipping...\n",
      "Serializing an answer here...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Found the following meanings (limited to 5 senses, unless you want more)<ul><li>(noun) A flying insect of the order Lepidoptera, distinguished from moths by their diurnal activity and generally brighter colouring.</li><li>(noun) A use of surgical tape, cut into thin strips and placed across an open wound to hold it closed.</li><li>(noun) The butterfly stroke.</li><li>(noun) A sensation of excited anxiety felt in the stomach.</li><li>(noun) Someone seen as being unserious and (originally) dressed  gaudily; someone flighty and unreliable.</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(grammar_2, \"define butterfly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'filter', 'type': 'number', 'value': 2}\n",
      "Current state of the entities:  <tools.answering.DefinitionEntity object at 0x7f340b6563d0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "More details on the item no. 2: <br><i>(noun)</i> A use of surgical tape, cut into thin strips and placed across an open wound to hold it closed.<br>Examples:<br><b>butterfly</b> tape"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_question(grammar_2, \"more about the second one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
