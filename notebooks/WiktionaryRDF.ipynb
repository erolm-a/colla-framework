{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet-Index test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "parquet_pos = os.path.join(os.getcwd(), \"data/wiktionary/parquet-index_2.11-0.4.1-SNAPSHOT.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "                        .config(\"spark.jars\", parquet_pos) \\\n",
    "                        .getOrCreate()\n",
    "\n",
    "# Add the python modules within the jar\n",
    "spark.sparkContext.addPyFile(parquet_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightcopy.index import QueryContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = QueryContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.providers import WiktionaryProvider\n",
    "\n",
    "provider = WiktionaryProvider()\n",
    "sample_1000 = os.path.join(\"data\", provider.get_filename_path(\"sample_1000\", \"parquet\"))\n",
    "context.index.create.mode('overwrite').indexBy(\"word\").parquet(sample_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.index.exists.parquet(sample_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiktionary_df_sample = context.index.parquet(sample_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(abbreviations=None, alternate=None, antonyms=None, categories=None, compounds=None, conjugation=None, derived=None, enum=None, heads=[Row(1='decolorat', 10=None, 11=None, 12=None, 13=None, 14=None, 2=None, 3=None, 4=None, 5=None, 6=None, 7=None, 8=None, 9=None, cat2=None, cat3=None, desc=None, f2qual=None, f3qual=None, f4qual=None, g=None, head=None, head2=None, past1=None, past2=None, past2_qual=None, past3=None, past3_qual=None, past4=None, past4_qual=None, past_ptc2=None, past_ptc2_qual=None, past_ptc3=None, past_ptc3_qual=None, past_ptc4=None, past_ptc4_qual=None, past_ptc5=None, past_ptc5_qual=None, past_ptc_qual=None, past_qual=None, pl=None, pl2qual=None, pl3qual=None, pl4qual=None, pl5qual=None, plqual=None, pres_3sg2=None, pres_3sg2_qual=None, pres_ptc2=None, pres_ptc2_qual=None, pres_ptc3=None, pres_ptc_qual=None, sc=None, sg=None, sort=None, suff=None, sup=None, sup1=None, sup2=None, sup3=None, sup4=None, template_name='en-verb', tr=None)], hypernyms=None, hyphenation=None, hyponyms=None, isbn=None, lang='English', pos='verb', pronunciations=None, redirect=None, related=None, senses=[Row(agent_of=None, alt_of=None, color=None, complex_inflection_of=None, examples=None, glosses=['To decolor; to deprive of color.'], holonyms=None, inflection_of=None, nonglosses=None, only_in=None, origin=None, senseid=None, tags=['transitive'], taxon=None, topics=None, unit=None, wikipedia=None)], synonyms=None, translations=None, word='decolorate')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiktionary_df_sample.filter('word == \"decolorate\"').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(col=Row(alt=None, lang='nl', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='kaper')),\n",
       " Row(col=Row(alt=None, lang='eo', roman=None, script=None, sense='someone who hijacks', tags=None, word='aerpirato')),\n",
       " Row(col=Row(alt=None, lang='de', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='Entführer')),\n",
       " Row(col=Row(alt=None, lang='de', roman=None, script=None, sense='someone who hijacks', tags=['f'], word='Entführerin')),\n",
       " Row(col=Row(alt=None, lang='nrf', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='haïjatcheux')),\n",
       " Row(col=Row(alt=None, lang='nb', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='kaprer')),\n",
       " Row(col=Row(alt=None, lang='nn', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='kaprar')),\n",
       " Row(col=Row(alt=None, lang='pl', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='porywacz')),\n",
       " Row(col=Row(alt=None, lang='ru', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='уго́нщик')),\n",
       " Row(col=Row(alt=None, lang='es', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='aeropirata')),\n",
       " Row(col=Row(alt=None, lang='es', roman=None, script=None, sense='someone who hijacks', tags=['m'], word='secuestrador'))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "hijacker_df.select(explode('translations')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.extractors import extract_form, extract_df\n",
    "\n",
    "hijacker_df = extract_form(extract_df(wiktionary_df_sample, 'hijacker'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the available namespaces in a handy dict\n",
    "from rdflib import Namespace, namespace\n",
    "\n",
    "namespaces = {\n",
    "    \"dct\": \"http://purl.org/dc/terms/\",\n",
    "    \"ontolex\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "    \"wikibase\": \"http://wikiba.se/ontology#\",\n",
    "    \"wd\": \"http://www.wikidata.org/entity/\",\n",
    "    \"wdt\": \"http://www.wikidata.org/prop/direct/\",\n",
    "    \"kgl\": \"http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/entity/\",\n",
    "    \"kgl-prop\": \"http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/property/\"\n",
    "}\n",
    "\n",
    "namespaces = dict((key, Namespace(val)) for (key, val) in namespaces.items())\n",
    "\n",
    "for ns in dir(namespace):\n",
    "    imported = getattr(namespace, ns)\n",
    "    if isinstance(imported, Namespace) or isinstance(imported, namespace.ClosedNamespace):\n",
    "        namespaces[ns.lower()] = imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dct': Namespace('http://purl.org/dc/terms/'),\n",
       " 'ontolex': Namespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#'),\n",
       " 'wikibase': Namespace('http://wikiba.se/ontology#'),\n",
       " 'wd': Namespace('http://www.wikidata.org/entity/'),\n",
       " 'wdt': Namespace('http://www.wikidata.org/prop/direct/'),\n",
       " 'kgl': Namespace('http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/entity/'),\n",
       " 'kgl-prop': Namespace('http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/property/'),\n",
       " 'csvw': Namespace('http://www.w3.org/ns/csvw#'),\n",
       " 'dc': Namespace('http://purl.org/dc/elements/1.1/'),\n",
       " 'dcat': Namespace('http://www.w3.org/ns/dcat#'),\n",
       " 'dcterms': Namespace('http://purl.org/dc/terms/'),\n",
       " 'doap': Namespace('http://usefulinc.com/ns/doap#'),\n",
       " 'foaf': rdf.namespace.ClosedNamespace('http://xmlns.com/foaf/0.1/'),\n",
       " 'odrl2': Namespace('http://www.w3.org/ns/odrl/2/'),\n",
       " 'org': Namespace('http://www.w3.org/ns/org#'),\n",
       " 'owl': Namespace('http://www.w3.org/2002/07/owl#'),\n",
       " 'prof': Namespace('http://www.w3.org/ns/dx/prof/'),\n",
       " 'prov': rdf.namespace.ClosedNamespace('http://www.w3.org/ns/prov#'),\n",
       " 'rdf': rdf.namespace.ClosedNamespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#'),\n",
       " 'rdfs': rdf.namespace.ClosedNamespace('http://www.w3.org/2000/01/rdf-schema#'),\n",
       " 'sdo': Namespace('https://schema.org/'),\n",
       " 'sh': Namespace('http://www.w3.org/ns/shacl#'),\n",
       " 'skos': rdf.namespace.ClosedNamespace('http://www.w3.org/2004/02/skos/core#'),\n",
       " 'sosa': Namespace('http://www.w3.org/ns/ssn/'),\n",
       " 'ssn': Namespace('http://www.w3.org/ns/sosa/'),\n",
       " 'time': Namespace('http://www.w3.org/2006/time#'),\n",
       " 'void': Namespace('http://rdfs.org/ns/void#'),\n",
       " 'xsd': Namespace('http://www.w3.org/2001/XMLSchema#')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "g = Graph()\n",
    "for k,v in namespaces.items():\n",
    "    g.bind(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mmh3\n",
    "\n",
    "def hash(word, pos):\n",
    "    return bytes.decode(base64.b32encode(mmh3.hash_bytes(word + pos))).rstrip(\"=\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgl = namespaces[\"kgl\"]\n",
    "kgl_prop = namespaces[\"kgl-prop\"]\n",
    "form_link = namespaces[\"ontolex\"].lexicalForm\n",
    "form_label = namespaces[\"ontolex\"].representation\n",
    "pos_link = kgl_prop.pos\n",
    "\n",
    "from rdflib import Literal\n",
    "\n",
    "def is_in_graph(x):\n",
    "    try:\n",
    "        next(g.triples((x, None, None)))\n",
    "        return True\n",
    "    except StopIteration:\n",
    "        return False\n",
    "\n",
    "\n",
    "def add_to_graph(word, senses, pos, noun_forms, adj_forms, verb_forms):\n",
    "    global g # I guess Python's GIL makes this thread-safe?\n",
    "    word_id = kgl[hash(word, pos)]\n",
    "    if not is_in_graph(word_id):\n",
    "        g.add((word_id, pos_link, kgl[pos]))\n",
    "        g.add((word_id, namespaces['rdfs'].label, Literal(word, lang=\"en\")))\n",
    "        \n",
    "    \n",
    "    # Detect collision by just looking at the word label.\n",
    "    # In theory we should also check that different pos may cause a collision\n",
    "    # but it looks extremely unlikely\n",
    "    else:\n",
    "        label = g.label(word_id)\n",
    "        if label != word:\n",
    "            print(f\"Collision detected between {label} and {word}\")\n",
    "            word_id = kgl[hash(word + \"$42\", pos)]\n",
    "            g.add((word_id, pos_link, kgl[pos]))\n",
    "            g.add((word_id, namespaces['rdfs'].label, Literal(word, lang=\"en\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, struct\n",
    "from pyspark.sql.types import NullType\n",
    "\n",
    "add_to_graph_udf = udf(lambda l: add_to_graph(*l), NullType())\n",
    "\n",
    "# This is dumb, but until I get SANSA or anything more decent to work...\n",
    "for row in hijacker_df.rdd.toLocalIterator():\n",
    "    add_to_graph(row['word'], row['senses'], row['pos'],\n",
    "                    row['noun_forms'], row['adj_forms'], row['verb_forms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/entity/qtyv2msjtvlufiegcbw4lvqlu4 http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/property/pos http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/entity/noun\n",
      "http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/entity/qtyv2msjtvlufiegcbw4lvqlu4 http://www.w3.org/2000/01/rdf-schema#label hijacker\n"
     ]
    }
   ],
   "source": [
    "for s,v,o in g.triples((None, None, None)):\n",
    "    print(s, v, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(rdflib.term.URIRef('http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/entityL1'),\n",
       " rdflib.term.URIRef('http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/propertypos'),\n",
       " rdflib.term.URIRef('http://knowledge-glue.ir.dcs.gla.ac.uk/ontology/entitynoun'))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g.triples((None, None, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
